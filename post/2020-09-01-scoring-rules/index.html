<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.2.0 for Hugo"><meta name=author content="Patrick Sadil"><meta name=description content="Bayes’ Rule gives that \(p(\theta|y) \propto p(\theta) p(y|\theta)\), that the posterior distribution, \(p(\theta|y)\) of the parameters, \(\theta\), is proportional to a prior distribution on those parameters, \(p(\theta)\), multiplied by the likelihood of the data, \(p(y|\theta)\). The rule specifies a procedure for using observed data, \(y\), to learn about the parameters, but it does not give a procedure for making decisions based on those parameters. In this dissertation, the statistical decisions are based primarily on the ability of different models to predict new data, \(\tilde{y}\), as approximated by PSIS-LOO+."><link rel=alternate hreflang=en-us href=https://psadil.github.io/psadil/post/2020-09-01-scoring-rules/><meta name=theme-color content="#1565c0"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/atom-one-dark.min.css crossorigin=anonymous title=hl-light media=print onload="this.media='all'"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/atom-one-dark.min.css crossorigin=anonymous title=hl-dark media=print onload="this.media='all'" disabled><link rel=stylesheet href=/psadil/css/wowchemy.8712747940cec16e23e865f32d8edfd9.css><script async src="https://www.googletagmanager.com/gtag/js?id=G-SP0TP763NP"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}function trackOutboundLink(a,b){gtag('event','click',{event_category:'outbound',event_label:a,transport_type:'beacon',event_callback:function(){b!=='_blank'&&(document.location=a)}}),console.debug("Outbound link clicked: "+a)}function onClickCallback(a){if(a.target.tagName!=='A'||a.target.host===window.location.host)return;trackOutboundLink(a.target,a.target.getAttribute('target'))}gtag('js',new Date),gtag('config','G-SP0TP763NP',{}),gtag('set',{cookie_flags:'SameSite=None;Secure'}),document.addEventListener('click',onClickCallback,!1)</script><link rel=manifest href=/psadil/index.webmanifest><link rel=icon type=image/png href=/psadil/media/icon_hu3896c2ce465988ba1fc8077f9a6388c6_268630_32x32_fill_lanczos_center_2.png><link rel=apple-touch-icon type=image/png href=/psadil/media/icon_hu3896c2ce465988ba1fc8077f9a6388c6_268630_180x180_fill_lanczos_center_2.png><link rel=canonical href=https://psadil.github.io/psadil/post/2020-09-01-scoring-rules/><meta property="twitter:card" content="summary"><meta property="twitter:site" content="@psadil"><meta property="twitter:creator" content="@psadil"><meta property="og:site_name" content="psadil"><meta property="og:url" content="https://psadil.github.io/psadil/post/2020-09-01-scoring-rules/"><meta property="og:title" content="scoring rules | psadil"><meta property="og:description" content="Bayes’ Rule gives that \(p(\theta|y) \propto p(\theta) p(y|\theta)\), that the posterior distribution, \(p(\theta|y)\) of the parameters, \(\theta\), is proportional to a prior distribution on those parameters, \(p(\theta)\), multiplied by the likelihood of the data, \(p(y|\theta)\). The rule specifies a procedure for using observed data, \(y\), to learn about the parameters, but it does not give a procedure for making decisions based on those parameters. In this dissertation, the statistical decisions are based primarily on the ability of different models to predict new data, \(\tilde{y}\), as approximated by PSIS-LOO+."><meta property="og:image" content="https://psadil.github.io/psadil/media/icon_hu3896c2ce465988ba1fc8077f9a6388c6_268630_512x512_fill_lanczos_center_2.png"><meta property="twitter:image" content="https://psadil.github.io/psadil/media/icon_hu3896c2ce465988ba1fc8077f9a6388c6_268630_512x512_fill_lanczos_center_2.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2020-09-01T00:00:00+00:00"><meta property="article:modified_time" content="2021-05-31T21:20:32-04:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://psadil.github.io/psadil/post/2020-09-01-scoring-rules/"},"headline":"scoring rules","datePublished":"2020-09-01T00:00:00Z","dateModified":"2021-05-31T21:20:32-04:00","author":{"@type":"Person","name":"Patrick Sadil"},"publisher":{"@type":"Organization","name":"psadil","logo":{"@type":"ImageObject","url":"https://psadil.github.io/psadil/media/icon_hu3896c2ce465988ba1fc8077f9a6388c6_268630_192x192_fill_lanczos_center_2.png"}},"description":"Bayes’ Rule gives that \\(p(\\theta|y) \\propto p(\\theta) p(y|\\theta)\\), that the posterior distribution, \\(p(\\theta|y)\\) of the parameters, \\(\\theta\\), is proportional to a prior distribution on those parameters, \\(p(\\theta)\\), multiplied by the likelihood of the data, \\(p(y|\\theta)\\). The rule specifies a procedure for using observed data, \\(y\\), to learn about the parameters, but it does not give a procedure for making decisions based on those parameters. In this dissertation, the statistical decisions are based primarily on the ability of different models to predict new data, \\(\\tilde{y}\\), as approximated by PSIS-LOO+."}</script><title>scoring rules | psadil</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=c1cf2232e7b3f86e59e471e83b8cdcb3><script src=/psadil/js/wowchemy-init.min.b8153d4570dcbb34350a2a846dba8c03.js></script><div class=page-header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/psadil/>psadil</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/psadil/>psadil</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/psadil/publication><span>Publications</span></a></li><li class=nav-item><a class="nav-link active" href=/psadil/post><span>Blog</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></div><div class=page-body><article class=article><div class="article-container pt-3"><h1>scoring rules</h1><div class=article-metadata><span class=article-date>Last updated on
May 31, 2021</span>
<span class=middot-divider></span><span class=article-reading-time>3 min read</span></div></div><div class=article-container><div class=article-style><script src=https://psadil.github.io/psadil/post/2020-09-01-scoring-rules/index.en_files/header-attrs/header-attrs.js></script><p>Bayes’ Rule gives that <span class="math inline">\(p(\theta|y) \propto p(\theta) p(y|\theta)\)</span>, that the posterior distribution, <span class="math inline">\(p(\theta|y)\)</span> of the parameters, <span class="math inline">\(\theta\)</span>, is proportional to a prior distribution on those parameters, <span class="math inline">\(p(\theta)\)</span>, multiplied by the likelihood of the data, <span class="math inline">\(p(y|\theta)\)</span>. The rule specifies a procedure for using observed data, <span class="math inline">\(y\)</span>, to learn about the parameters, but it does not give a procedure for making decisions based on those parameters. In this dissertation, the statistical decisions are based primarily on the ability of different models to predict new data, <span class="math inline">\(\tilde{y}\)</span>, as approximated by PSIS-LOO+. However, this approach is relatively rare in cognitive psychology. The notation closely follows that of <span class=citation>[@vehtari_practical_2017]</span>.</p><p>Currently in Psychology, the strategy is to rely on Bayes’ Factors. There are a few different ways to view Bayes’ Factors. I’m going to question whether Bayes’ Factors are actually a good way to choose a new model.</p><p>There are a few different ways to motivate Bayes’ factors. One simple strategy comes from an application of Bayes’ rule. If we have a model, <span class="math inline">\(M\)</span>, we can ask a question like: what is the probability of a model, given that we’ve observed data? This gives the relationship</p><p><span class="math display">\[
p(M|y) = \frac{p(y|M)p(M)}{p(y)}
\]</span></p><p>This relationship is not, by itself, particularly helpful. There is approximately 0 chance that we’ve specified exactly the right model, so any calculation that allowed <span class="math inline">\(p(M|y) > 0\)</span> should immediately be suspect. But if we have two models, <span class="math inline">\(M_0\)</span> and <span class="math inline">\(M_1\)</span>, it makes a bit of sense to talk about the relative probability of each model.</p><p><span class="math display">\[
\frac{p(M_1|y)}{p(M_0|y)} = \underbrace{\frac{p(y|M_1)}{p(y|M_0)}}_{\text{Bayes Factor}} \frac{p(M_1)}{p(M_0)}
\]</span></p><p>Assuming that the prior probability associated with each model are equal, then this ratio of posterior is driven entirely by the ratio of likelihoods of the data under each of the different models. However, it is again questionable whether this relationship practical makes sense to calculate. As before, I have no faith that the models I’ve specified are literally the truth, so for me <span class="math inline">\(p(M_0)\)</span> is 0. Just because these are the two models I’m currently willing to entertain does not mean that I think they are actually true (after all, <em>all</em> models are wrong…).</p><p>But let’s assume that we’re talking about some small world, where all statements are qualified with the assumption that one of these two models are true.</p><p>Now we step into a tricky part of language. It is common to talk about a model’s ‘predictions’ in reference to how well the model can capture the already observed data. This language leads some authors to talk about Bayes’ factor as a measure of the (relative) ‘predictive accuracy’ of a model.</p><p>By the chain rule, the implied predictions can also be viewed sequentially [waiting on book to see whether this is relevant]</p><p><span class="math display">\[
p(y|M) = p(y_1|M)p(y_2|M,y_1)\ldots p(y_n | M,y_1,y_2,\ldots,y_{n-1})
\]</span></p><p>:A distribution indicating what new data are likely under a posterior distribution. <span class="math inline">\(p(\tilde{y}_i | y) = \int p(\tilde{y}_i|\theta)p(\theta | y) d \theta\)</span>. Note that the distribution is for a single new observation, <span class="math inline">\(\tilde{y}_i\)</span>.</p><p>: Expected log, pointwise predictive density. This is an expectation of the log score of the posterior predictive distribution for each observation, summed across all observations in a dataset: $_{i=1}^{n} p_t(_i)(_i | y ) d _i $. The distribution <span class="math inline">\(p_t(\tilde{y}_i)\)</span> is the true (unknown) data-generating distribution for observation <span class="math inline">\(\tilde{y}_i\)</span> . Roughly, the ELPD measures the predictive ability of a model by first scoring how likely a model “thinks” a particular observation will be (through the log of the posterior predictive distribution), then weighting that score by the probability of observing that observation (through the true, data generating distribution), and finally combining these weighted scores across all possible values of each observation and all observations in a dataset (the integration and summation).</p></div><p class=edit-page><a href=https://github.com/psadil/psadil/blob/main/content/post/2020-09-01-scoring-rules/index.en.Rmd>View Page Source</a></p><div class=share-box aria-hidden=true><ul class=share><li><a href="https://twitter.com/intent/tweet?url=https://psadil.github.io/psadil/post/2020-09-01-scoring-rules/&text=scoring%20rules" target=_blank rel=noopener class=share-btn-twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=https://psadil.github.io/psadil/post/2020-09-01-scoring-rules/&t=scoring%20rules" target=_blank rel=noopener class=share-btn-facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=scoring%20rules&body=https://psadil.github.io/psadil/post/2020-09-01-scoring-rules/" target=_blank rel=noopener class=share-btn-email><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=https://psadil.github.io/psadil/post/2020-09-01-scoring-rules/&title=scoring%20rules" target=_blank rel=noopener class=share-btn-linkedin><i class="fab fa-linkedin-in"></i></a></li><li><a href="whatsapp://send?text=scoring%20rules%20https://psadil.github.io/psadil/post/2020-09-01-scoring-rules/" target=_blank rel=noopener class=share-btn-whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=https://psadil.github.io/psadil/post/2020-09-01-scoring-rules/&title=scoring%20rules" target=_blank rel=noopener class=share-btn-weibo><i class="fab fa-weibo"></i></a></li></ul></div><div class="media author-card content-widget-hr"><a href=https://psadil.github.io/psadil/><img class="avatar mr-3 avatar-circle" src="https://s.gravatar.com/avatar/6e7d3d145f872ee736e7714ceb8265c6?s=200" alt="Patrick Sadil"></a><div class=media-body><h5 class=card-title><a href=https://psadil.github.io/psadil/>Patrick Sadil</a></h5><h6 class=card-subtitle>Post-Doctoral Researcher</h6><p class=card-text>Patrick is an academic researcher at the University of Massachusetts, Amherst.</p><ul class=network-icon aria-hidden=true><li><a href=mailto:psadil@gmail.com><i class="fas fa-envelope"></i></a></li><li><a href=https://psadil.github.io/cv/cv.pdf target=_blank rel=noopener><i class="ai ai-cv"></i></a></li><li><a href=//orcid.org/0000-0003-4141-1343><i class="ai ai-orcid"></i></a></li><li><a href="https://scholar.google.co.uk/citations?user=HhPeElcAAAAJ" target=_blank rel=noopener><i class="ai ai-google-scholar"></i></a></li><li><a href=https://gitlab.com/psadil target=_blank rel=noopener><i class="fab fa-gitlab"></i></a></li><li><a href=https://github.com/psadil target=_blank rel=noopener><i class="fab fa-github"></i></a></li></ul></div></div></div></article></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by><a href=/psadil/privacy/>Privacy Policy</a>
&#183;
<a href=/psadil/terms/>Terms</a></p><p class=powered-by>© 2021 Patrick Sadil</p><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-modules target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/matlab.min.js></script><script src=/psadil/js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js></script><script src=/psadil/en/js/wowchemy.min.c7dbcd0a03997d954a216caf59fc7681.js></script></body></html>