<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.2.0 for Hugo"><meta name=author content="Patrick Sadil"><meta name=description content="Functional magnetic resonance imaging records brain activity with spatially distinct voxels, but this segmentation will be misaligned with a brain’s meaningful boundaries. The segmentation results in some voxels recording activity from different types of tissue – types that are both neural an non-neural – but even voxels that exclusively sample gray matter can span functionally distinct cortex. For example, a 3T scanner allows voxels in the range of 1."><link rel=alternate hreflang=en-us href=https://psadil.github.io/psadil/post/forward-encoding-model/><link rel=preconnect href=https://fonts.gstatic.com crossorigin><meta name=theme-color content="#1565c0"><script src=/psadil/js/mathjax-config.js></script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/atom-one-dark.min.css crossorigin=anonymous title=hl-light media=print onload="this.media='all'"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/atom-one-dark.min.css crossorigin=anonymous title=hl-dark media=print onload="this.media='all'" disabled><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Atkinson+Hyperlegible:ital,wght@0,400;0,700;1,400;1,700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Atkinson+Hyperlegible:ital,wght@0,400;0,700;1,400;1,700&display=swap" media=print onload="this.media='all'"><link rel=stylesheet href=/psadil/css/wowchemy.8bc78ecea639e288ab749bc0faab617c.css><script async src="https://www.googletagmanager.com/gtag/js?id=G-SP0TP763NP"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}function trackOutboundLink(a,b){gtag('event','click',{event_category:'outbound',event_label:a,transport_type:'beacon',event_callback:function(){b!=='_blank'&&(document.location=a)}}),console.debug("Outbound link clicked: "+a)}function onClickCallback(a){if(a.target.tagName!=='A'||a.target.host===window.location.host)return;trackOutboundLink(a.target,a.target.getAttribute('target'))}gtag('js',new Date),gtag('config','G-SP0TP763NP',{}),gtag('set',{cookie_flags:'SameSite=None;Secure'}),document.addEventListener('click',onClickCallback,!1)</script><link rel=manifest href=/psadil/index.webmanifest><link rel=icon type=image/png href=/psadil/media/icon_hu3896c2ce465988ba1fc8077f9a6388c6_268630_32x32_fill_lanczos_center_2.png><link rel=apple-touch-icon type=image/png href=/psadil/media/icon_hu3896c2ce465988ba1fc8077f9a6388c6_268630_180x180_fill_lanczos_center_2.png><link rel=canonical href=https://psadil.github.io/psadil/post/forward-encoding-model/><meta property="twitter:card" content="summary"><meta property="twitter:site" content="@psadil"><meta property="twitter:creator" content="@psadil"><meta property="og:site_name" content="psadil"><meta property="og:url" content="https://psadil.github.io/psadil/post/forward-encoding-model/"><meta property="og:title" content="Forward encoding model | psadil"><meta property="og:description" content="Functional magnetic resonance imaging records brain activity with spatially distinct voxels, but this segmentation will be misaligned with a brain’s meaningful boundaries. The segmentation results in some voxels recording activity from different types of tissue – types that are both neural an non-neural – but even voxels that exclusively sample gray matter can span functionally distinct cortex. For example, a 3T scanner allows voxels in the range of 1."><meta property="og:image" content="https://psadil.github.io/psadil/media/icon_hu3896c2ce465988ba1fc8077f9a6388c6_268630_512x512_fill_lanczos_center_2.png"><meta property="twitter:image" content="https://psadil.github.io/psadil/media/icon_hu3896c2ce465988ba1fc8077f9a6388c6_268630_512x512_fill_lanczos_center_2.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2019-10-24T00:00:00+00:00"><meta property="article:modified_time" content="2024-07-09T10:34:11-04:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://psadil.github.io/psadil/post/forward-encoding-model/"},"headline":"Forward encoding model","datePublished":"2019-10-24T00:00:00Z","dateModified":"2024-07-09T10:34:11-04:00","author":{"@type":"Person","name":"Patrick Sadil"},"publisher":{"@type":"Organization","name":"psadil","logo":{"@type":"ImageObject","url":"https://psadil.github.io/psadil/media/icon_hu3896c2ce465988ba1fc8077f9a6388c6_268630_192x192_fill_lanczos_center_2.png"}},"description":"Functional magnetic resonance imaging records brain activity with spatially distinct voxels, but this segmentation will be misaligned with a brain’s meaningful boundaries. The segmentation results in some voxels recording activity from different types of tissue – types that are both neural an non-neural – but even voxels that exclusively sample gray matter can span functionally distinct cortex. For example, a 3T scanner allows voxels in the range of 1."}</script><title>Forward encoding model | psadil</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=b42a88b9fb6759168715f22b15d6803c><script src=/psadil/js/wowchemy-init.min.b8153d4570dcbb34350a2a846dba8c03.js></script><div class=page-header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/psadil/>psadil</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/psadil/>psadil</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/psadil/publication><span>Publications</span></a></li><li class=nav-item><a class="nav-link active" href=/psadil/post><span>Blog</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></div><div class=page-body><article class=article><div class="article-container pt-3"><h1>Forward encoding model</h1><div class=article-metadata><span class=article-date>Last updated on
Jul 9, 2024</span>
<span class=middot-divider></span><span class=article-reading-time>6 min read</span></div></div><div class=article-container><div class=article-style><script src=https://psadil.github.io/psadil/post/forward-encoding-model/index_files/header-attrs/header-attrs.js></script><p>Functional magnetic resonance imaging records brain activity with spatially distinct voxels, but this segmentation will be misaligned with a brain’s meaningful boundaries. The segmentation results in some voxels recording activity from different types of tissue – types that are both neural an non-neural – but even voxels that exclusively sample gray matter can span functionally distinct cortex. For example, a 3T scanner allows voxels in the range of 1.5-3 mm<span class="math inline">\(^3\)</span>, but orientation columns have an average width of 0.8 mm <span class=citation>(<a href=#ref-yacoub2008 role=doc-biblioref>Yacoub, Harel, and Uğurbil 2008</a>)</span>. Studying orientation columns with such low resolution requires statistical tools.</p><p>One statistical tool models voxel activity as a linear combination of the activity of a small number of neural channels <span class=citation>(<a href=#ref-brouwer2009 role=doc-biblioref>Brouwer and Heeger 2009</a>; <a href=#ref-kay2008 role=doc-biblioref>Kay et al. 2008</a>)</span>. These models are called forward models, describing how the channel activity transforms into voxel activity. In early sensory cortex, the channels are analogous to cortical columns. In later cortex, the channels are more abstract dimensions of a representational space. Developing a forward model requires assuming not only how many channels contribute of a voxel’s activity, but also the tuning properties of those channels. With these assumptions, regression allows inferring the contribution of each channel to each voxel’s activity. Let <span class="math inline">\(N\)</span> be the number of observations for each voxel, <span class="math inline">\(M\)</span> be the number of voxels, and <span class="math inline">\(K\)</span> be the number of channels within a voxel. The forward model specifies that the data (<span class="math inline">\(B\)</span>, <span class="math inline">\(M \times N\)</span>) result from a weighted combination of the assumed channels responses (<span class="math inline">\(C\)</span>, <span class="math inline">\(K \times N\)</span>), where the weights (<span class="math inline">\(W\)</span>, <span class="math inline">\(M \times K\)</span>) are unknown.</p><p><span class="math display">\[
B = WC
\]</span></p><p>Taking the pseudoinverse of the channel matrix and multiplying the result by the data gives an estimate of the weight matrix:</p><p><span class="math display">\[
\widehat{W} = BC^T(CC^T)^{-1}
\]</span></p><p>Assumptions about <span class="math inline">\(C\)</span> are assumptions about how the channels encode stimuli. Different encoding schemes can be instantiated with different <span class="math inline">\(C\)</span>, and any method for comparing linear models could be used to compare the schemes.</p><p>The forward encoding model enables comparison of static encoding schemes, but neural encoding schemes are dynamic. Attentional fluctuations, perceptual learning, and stimulation history all modulate neural tuning functions <span class=citation>(<a href=#ref-mcadams1999 role=doc-biblioref>McAdams and Maunsell 1999</a>; <a href=#ref-reynolds2000 role=doc-biblioref>Reynolds, Pasternak, and Desimone 2000</a>; <a href=#ref-siegel2015 role=doc-biblioref>Siegel, Buschman, and Miller 2015</a>; <a href=#ref-yang2004 role=doc-biblioref>Yang and Maunsell 2004</a>)</span>. To explore modulations with functional magnetic resonance imaging, some researchers have inverted the encoding model <span class=citation>(<a href=#ref-garcia2013 role=doc-biblioref>Garcia, Srinivasan, and Serences 2013</a>; <a href=#ref-rahmati2018 role=doc-biblioref>Rahmati, Saber, and Curtis 2018</a>; <a href=#ref-saproo2014 role=doc-biblioref>Saproo and Serences 2014</a>; <a href=#ref-scolari2012 role=doc-biblioref>Scolari, Byers, and Serences 2012</a>; <a href=#ref-sprague2013 role=doc-biblioref>Sprague and Serences 2013</a>; <a href=#ref-vo2017 role=doc-biblioref>Vo, Sprague, and Serences 2017</a>)</span>. The inversion is a variation of cross validation. The method estimates the weight matrix with only some of the data (e.g., all data excluding a single run). The held out data, <span class="math inline">\(B_H\)</span>, contains observations from all experimental condition across which the tuning functions might vary. The encoding model is inverted by multiplying the pseudoinverse of the weight matrix with the held out data to estimate a new channel response matrix.</p><p><span class="math display">\[
\widehat{C} = \widehat{W}^T(\widehat{W}\widehat{W}^T)^{-1}B_H
\]</span></p><p>The new channel response matrix estimates how the channels respond in each experimental condition.</p><p>Although validation studies demonstrated that the inverted encoding model enables inferences that recapitulate some modulations observed with electrophysiology <span class=citation>(<a href=#ref-sprague2018 role=doc-biblioref>Sprague et al. 2018</a>; <a href=#ref-sprague2015 role=doc-biblioref>Sprague, Saproo, and Serences 2015</a>)</span>, the inversion also misleads inferences about certain fundamental modulations <span class=citation>(<a href=#ref-gardner2019 role=doc-biblioref>Gardner and Liu 2019</a>; <a href=#ref-liu2018 role=doc-biblioref>Liu, Cable, and Gardner 2018</a>)</span>. In particular, increasing the contrast of an orientation increases the gain of neurons tuned to orientation without altering their tuning bandwidth <span class=citation>(<a href=#ref-alitto2004 role=doc-biblioref>Alitto and Usrey 2004</a>; <a href=#ref-sclar1982 role=doc-biblioref>Sclar and Freeman 1982</a>; <a href=#ref-skottun1987 role=doc-biblioref>Skottun et al. 1987</a>)</span>, but the inverted encoding model (incorrectly) suggests that higher contrast decreases bandwidth <span class=citation>(<a href=#ref-liu2018 role=doc-biblioref>Liu, Cable, and Gardner 2018</a>)</span>. Inferences are misled because the estimated channel responses are constrained by the initial assumptions about <span class="math inline">\(C\)</span> <span class=citation>(<a href=#ref-gardner2019 role=doc-biblioref>Gardner and Liu 2019</a>)</span>. Using the encoding model to study modulations requires a way to estimate the contribution of each channel without assuming a fixed channel response function.</p><div id=references class="section level1 unnumbered"><h1>References</h1><div id=refs class="references csl-bib-body hanging-indent"><div id=ref-alitto2004 class=csl-entry>Alitto, Henry J, and W Martin Usrey. 2004. <span>“Influence of Contrast on Orientation and Temporal Frequency Tuning in Ferret Primary Visual Cortex.”</span> <em>Journal of Neurophysiology</em> 91 (6): 2797–2808.</div><div id=ref-brouwer2009 class=csl-entry>Brouwer, Gijs Joost, and David J Heeger. 2009. <span>“Decoding and Reconstructing Color from Responses in Human Visual Cortex.”</span> <em>Journal of Neuroscience</em> 29 (44): 13992–4003.</div><div id=ref-garcia2013 class=csl-entry>Garcia, Javier O, Ramesh Srinivasan, and John T Serences. 2013. <span>“Near-Real-Time Feature-Selective Modulations in Human Cortex.”</span> <em>Current Biology</em> 23 (6): 515–22.</div><div id=ref-gardner2019 class=csl-entry>Gardner, Justin L, and Taosheng Liu. 2019. <span>“Inverted Encoding Models Reconstruct an Arbitrary Model Response, Not the Stimulus.”</span> <em>eNeuro</em> 6 (2).</div><div id=ref-kay2008 class=csl-entry>Kay, Kendrick N, Thomas Naselaris, Ryan J Prenger, and Jack L Gallant. 2008. <span>“Identifying Natural Images from Human Brain Activity.”</span> <em>Nature</em> 452 (7185): 352.</div><div id=ref-liu2018 class=csl-entry>Liu, Taosheng, Dylan Cable, and Justin L Gardner. 2018. <span>“Inverted Encoding Models of Human Population Response Conflate Noise and Neural Tuning Width.”</span> <em>Journal of Neuroscience</em> 38 (2): 398–408.</div><div id=ref-mcadams1999 class=csl-entry>McAdams, Carrie J, and John HR Maunsell. 1999. <span>“Effects of Attention on Orientation-Tuning Functions of Single Neurons in Macaque Cortical Area V4.”</span> <em>Journal of Neuroscience</em> 19 (1): 431–41.</div><div id=ref-rahmati2018 class=csl-entry>Rahmati, Masih, Golbarg T Saber, and Clayton E Curtis. 2018. <span>“Population Dynamics of Early Visual Cortex During Working Memory.”</span> <em>Journal of Cognitive Neuroscience</em> 30 (2): 219–33.</div><div id=ref-reynolds2000 class=csl-entry>Reynolds, John H, Tatiana Pasternak, and Robert Desimone. 2000. <span>“Attention Increases Sensitivity of V4 Neurons.”</span> <em>Neuron</em> 26 (3): 703–14.</div><div id=ref-saproo2014 class=csl-entry>Saproo, Sameer, and John T Serences. 2014. <span>“Attention Improves Transfer of Motion Information Between V1 and MT.”</span> <em>Journal of Neuroscience</em> 34 (10): 3586–96.</div><div id=ref-sclar1982 class=csl-entry>Sclar, G, and RD Freeman. 1982. <span>“Orientation Selectivity in the Cat’s Striate Cortex Is Invariant with Stimulus Contrast.”</span> <em>Experimental Brain Research</em> 46 (3): 457–61.</div><div id=ref-scolari2012 class=csl-entry>Scolari, Miranda, Anna Byers, and John T Serences. 2012. <span>“Optimal Deployment of Attentional Gain During Fine Discriminations.”</span> <em>Journal of Neuroscience</em> 32 (22): 7723–33.</div><div id=ref-siegel2015 class=csl-entry>Siegel, Markus, Timothy J Buschman, and Earl K Miller. 2015. <span>“Cortical Information Flow During Flexible Sensorimotor Decisions.”</span> <em>Science</em> 348 (6241): 1352–55.</div><div id=ref-skottun1987 class=csl-entry>Skottun, Bernt C, Arthur Bradley, Gary Sclar, Izumi Ohzawa, and Ralph D Freeman. 1987. <span>“The Effects of Contrast on Visual Orientation and Spatial Frequency Discrimination: A Comparison of Single Cells and Behavior.”</span> <em>Journal of Neurophysiology</em> 57 (3): 773–86.</div><div id=ref-sprague2018 class=csl-entry>Sprague, Thomas C, Kirsten CS Adam, Joshua J Foster, Masih Rahmati, David W Sutterer, and Vy A Vo. 2018. <span>“Inverted Encoding Models Assay Population-Level Stimulus Representations, Not Single-Unit Neural Tuning.”</span> <em>eNeuro</em> 5 (3).</div><div id=ref-sprague2015 class=csl-entry>Sprague, Thomas C, Sameer Saproo, and John T Serences. 2015. <span>“Visual Attention Mitigates Information Loss in Small-and Large-Scale Neural Codes.”</span> <em>Trends in Cognitive Sciences</em> 19 (4): 215–26.</div><div id=ref-sprague2013 class=csl-entry>Sprague, Thomas C, and John T Serences. 2013. <span>“Attention Modulates Spatial Priority Maps in the Human Occipital, Parietal and Frontal Cortices.”</span> <em>Nature Neuroscience</em> 16 (12): 1879.</div><div id=ref-vo2017 class=csl-entry>Vo, Vy A, Thomas C Sprague, and John T Serences. 2017. <span>“Spatial Tuning Shifts Increase the Discriminability and Fidelity of Population Codes in Visual Cortex.”</span> <em>Journal of Neuroscience</em> 37 (12): 3386–3401.</div><div id=ref-yacoub2008 class=csl-entry>Yacoub, Essa, Noam Harel, and Kâmil Uğurbil. 2008. <span>“High-Field fMRI Unveils Orientation Columns in Humans.”</span> <em>Proceedings of the National Academy of Sciences</em> 105 (30): 10607–12.</div><div id=ref-yang2004 class=csl-entry>Yang, Tianming, and John HR Maunsell. 2004. <span>“The Effect of Perceptual Learning on Neuronal Responses in Monkey Visual Area V4.”</span> <em>Journal of Neuroscience</em> 24 (7): 1617–26.</div></div></div></div><p class=edit-page><a href=https://github.com/psadil/psadil/blob/main/content/post/2019-10-24-forward-encoding-model/index.Rmd>View Page Source</a></p><div class=article-tags><a class="badge badge-light" href=/psadil/tag/fmri/>fmri</a></div><div class=share-box aria-hidden=true><ul class=share><li><a href="https://twitter.com/intent/tweet?url=https://psadil.github.io/psadil/post/forward-encoding-model/&text=Forward%20encoding%20model" target=_blank rel=noopener class=share-btn-twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=https://psadil.github.io/psadil/post/forward-encoding-model/&t=Forward%20encoding%20model" target=_blank rel=noopener class=share-btn-facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=Forward%20encoding%20model&body=https://psadil.github.io/psadil/post/forward-encoding-model/" target=_blank rel=noopener class=share-btn-email><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=https://psadil.github.io/psadil/post/forward-encoding-model/&title=Forward%20encoding%20model" target=_blank rel=noopener class=share-btn-linkedin><i class="fab fa-linkedin-in"></i></a></li><li><a href="whatsapp://send?text=Forward%20encoding%20model%20https://psadil.github.io/psadil/post/forward-encoding-model/" target=_blank rel=noopener class=share-btn-whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=https://psadil.github.io/psadil/post/forward-encoding-model/&title=Forward%20encoding%20model" target=_blank rel=noopener class=share-btn-weibo><i class="fab fa-weibo"></i></a></li></ul></div><div class="media author-card content-widget-hr"><a href=https://psadil.github.io/psadil/><img class="avatar mr-3 avatar-circle" src="https://s.gravatar.com/avatar/3c65844f0569ce42e93153c270c2daed?s=200" alt="Patrick Sadil"></a><div class=media-body><h5 class=card-title><a href=https://psadil.github.io/psadil/>Patrick Sadil</a></h5><h6 class=card-subtitle>Research Associate; Biostatistics Faculty</h6><ul class=network-icon aria-hidden=true><li><a href=mailto:psadil1@jh.edu><i class="fas fa-envelope"></i></a></li><li><a href=https://psadil.github.io/cv/cv.pdf target=_blank rel=noopener><i class="ai ai-cv"></i></a></li><li><a href=//orcid.org/0000-0003-4141-1343><i class="ai ai-orcid"></i></a></li><li><a href="https://scholar.google.co.uk/citations?user=HhPeElcAAAAJ" target=_blank rel=noopener><i class="ai ai-google-scholar"></i></a></li><li><a href=https://github.com/psadil target=_blank rel=noopener><i class="fab fa-github"></i></a></li></ul></div></div></div></article></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by><a href=/psadil/privacy/>Privacy Policy</a>
&#183;
<a href=/psadil/terms/>Terms</a></p><p class=powered-by>© 2024 Patrick Sadil</p><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-modules target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/matlab.min.js></script><script src=/psadil/js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js></script><script src=/psadil/en/js/wowchemy.min.c7dbcd0a03997d954a216caf59fc7681.js></script></body></html>