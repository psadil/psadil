<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>dissertation | psadil</title><link>https://psadil.github.io/psadil/category/dissertation/</link><atom:link href="https://psadil.github.io/psadil/category/dissertation/index.xml" rel="self" type="application/rss+xml"/><description>dissertation</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2021 Patrick Sadil</copyright><lastBuildDate>Fri, 15 Nov 2019 00:00:00 +0000</lastBuildDate><image><url>https://psadil.github.io/psadil/media/icon_hu3896c2ce465988ba1fc8077f9a6388c6_268630_512x512_fill_lanczos_center_2.png</url><title>dissertation</title><link>https://psadil.github.io/psadil/category/dissertation/</link></image><item><title>Half of a parameter</title><link>https://psadil.github.io/psadil/post/half-of-a-parameter/</link><pubDate>Fri, 15 Nov 2019 00:00:00 +0000</pubDate><guid>https://psadil.github.io/psadil/post/half-of-a-parameter/</guid><description>
&lt;script src="https://psadil.github.io/psadil/post/half-of-a-parameter/index_files/header-attrs/header-attrs.js">&lt;/script>
&lt;p>Science produces models that provide parsimonious descriptions of the world. In cognitive psychology, models regularly compete to explain a few phenomena. But models can survive experiment after experiment, both because of the difficulty of capturing participant’s nuanced behavior, and because models often make highly overlapping predictions. In these cases, a model succeeds through its relative parsimony.&lt;/p>
&lt;p>In cognitive psychology, measures of information criteria, specifically Akaike’s and the Bayesian information criteria &lt;span class="citation">(&lt;a href="#ref-schwarz1978" role="doc-biblioref">Schwarz 1978&lt;/a>; &lt;a href="#ref-akaike1998" role="doc-biblioref">Akaike 1973&lt;/a>)&lt;/span>, determine a winning model. These criteria measure complexity by tallying the number of parameters in a model. Long maths and specific assumptions justify the claim that a model with more parameters is more complex than a model with fewer parameters, and so does our intuition that a model is complex if it has many moving parts. Unfortunately, the assumptions fail in common situations, such as when the models are fit in a Bayesian rather than frequentist setting. An alphabet soup of other information criteria exists (in addition to Akaike’s the Bayesian criteria, there is the DIC, WAIC, KIC, NIC, TIC, etc), and these other criteria assign complexity more complexly. These criteria are sensitive not only to the number of parameters in a model but also to the varied roles that a parameter can have. They assign the complexity of a model based on the model’s number of ‘effective parameters.’&lt;/p>
&lt;p>For intuition on why tallying the number of parameters is an insufficient measure complexity, consider two models of response time. Both models assume that response times are distributed according to a normal distribution. In this simple example, the variability of the distributions are known, and so the models have only a single free parameter, which is the average response time. In one model, that average can be any number, a value from negative to positive infinity. This is the kind of model implicitly assumed when we conduct a t-test on the averages of response times. Of course the model is a simplification of response times, but this model also has the glaring flaw that it allows the average response time to be negative; a participant cannot respond to stimulation before the stimulus appears. The second model addresses this flaw by adding the constraint that the average response time cannot be negative. Although the second model is more constrained, the models have the same number of parameters. The second model can only account for half of the patterns of data as the first; the second model is twice as parsimonious as the first &lt;span class="citation">(&lt;a href="#ref-gelman2014" role="doc-biblioref">Gelman, Hwang, and Vehtari 2014&lt;/a>)&lt;/span>. To adjudicate between these model requires a measure that is sensitive to complexity but does not simply tally the number of parameters in each model.&lt;/p>
&lt;div id="references" class="section level1 unnumbered">
&lt;h1>References&lt;/h1>
&lt;div id="refs" class="references csl-bib-body hanging-indent">
&lt;div id="ref-akaike1998" class="csl-entry">
Akaike, Hirotogu. 1973. &lt;span>“Information Theory and an Extension of the Maximum Likelihood Principle.”&lt;/span> In &lt;em>Proceedings of the Second International Symposium on Information Theory&lt;/em>, 267–81.
&lt;/div>
&lt;div id="ref-gelman2014" class="csl-entry">
Gelman, Andrew, Jessica Hwang, and Aki Vehtari. 2014. &lt;span>“Understanding Predictive Information Criteria for &lt;span>Bayesian&lt;/span> Models.”&lt;/span> &lt;em>Statistics and Computing&lt;/em> 24 (6): 997–1016. &lt;a href="https://doi.org/10.1007/s11222-013-9416-2">https://doi.org/10.1007/s11222-013-9416-2&lt;/a>.
&lt;/div>
&lt;div id="ref-schwarz1978" class="csl-entry">
Schwarz, Gideon. 1978. &lt;span>“Estimating the Dimension of a Model.”&lt;/span> &lt;em>The Annals of Statistics&lt;/em> 6 (2): 461–64. &lt;a href="https://doi.org/10.1214/aos/1176344136">https://doi.org/10.1214/aos/1176344136&lt;/a>.
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Staircases for Thresholds, Part 2</title><link>https://psadil.github.io/psadil/post/staircases-for-thresholds-part2/</link><pubDate>Fri, 08 Nov 2019 00:00:00 +0000</pubDate><guid>https://psadil.github.io/psadil/post/staircases-for-thresholds-part2/</guid><description>
&lt;script src="https://psadil.github.io/psadil/post/staircases-for-thresholds-part2/index_files/header-attrs/header-attrs.js">&lt;/script>
&lt;!--Incantation to add equation numbers
https://stackoverflow.com/questions/35026405/auto-number-equations-in-r-markdown-documents-in-rstudio-->
&lt;script type="text/x-mathjax-config">
MathJax.Hub.Config({
TeX: {
equationNumbers: {
autoNumber: "ams"
}
}
});
&lt;/script>
&lt;p>In last week’s post, I discussed how some experiments in cognitive psychology require researchers to pick a differently intense stimulus for each participant. In particular, I discussed a procedure for picking an intensity that elicits positive responses on approximately half of trials, the staircase procedure. In the staircase procedure, the researcher increases the intensity after every positive response and decreases the intensity after every negative response. If the participant completes another set of trials in which the intensity is fixed to the average of the intensities that were used during the staircase, the participant will provide positive responses approximately half of the time. But a researcher may want participants to give positive responses with a different proportion. A different proportion of responses can be achieved by transforming the staircase &lt;span class="citation">(&lt;a href="#ref-levitt1997" role="doc-biblioref">Levitt 1971&lt;/a>)&lt;/span>.&lt;/p>
&lt;p>The original staircase produced an intensity that elicited half positive responses by balancing the proportion of positive and negative responses. Intuitively, to elicit a higher proportion of positive responses, the transformed staircase must tilt this balance by converging on a more intense stimulus. Any staircase affects responses by changing the stimulus intensity as a function of how participants behave. The staircase that changes the intensity after every response is called a one-up, one-down staircase; one negative response causes the intensity to go up, one positive response causes the intensity to go down. A transformed staircase can make a positive response more likely by making intensity decreases less likely. The names of transformed staircases are analogous to the one-up, one-down label: a one-up, two-down staircase increases the stimulus after any negative response and decreases the intensity after two positive responses; a two-up, three-down staircase increases the intensity after two negative responses and only decreases the intensity after three positive responses; and so on. Altering when the staircase increments the intensity alters the intensity at which the staircase converges.&lt;/p>
&lt;p>We can use algebra to calculate the proportion of positive responses elicited by the intensity converged on by a staircase. As an example, consider a staircase that increases the intensity after a single positive response but decreases the intensity after two negative responses, a one-up, two-down staircase. Since the one-up, two-down regime results in fewer decreases than the one-up, one-down staircase, we should expect that the proportion of positive responses will be higher than half. For the calculation, note that there are three possible sequences of responses that result in an intensity change. Two of these sequences cause an increase, either a single negative or a positive followed by a negative. For the algebra later, let &lt;span class="math inline">\(p(x|i)\)&lt;/span> be the probability of obtaining a positive response at stimulus intensity, &lt;span class="math inline">\(i\)&lt;/span>. Our goal is to solve for this probability. Participants can only provide either positive or negative responses, so the probability of obtaining a negative response to that stimulus is &lt;span class="math inline">\(1-p(x|i)\)&lt;/span>. The probability of increasing the stimulus intensity away from intensity &lt;span class="math inline">\(i\)&lt;/span>, &lt;span class="math inline">\(p(\text{up|i})\)&lt;/span> is the sum of the probabilities for the two sequences:&lt;/p>
&lt;p>&lt;span class="math display">\[
\begin{equation}
p(\text{up|i}) = (1-p(x|i)) + p(x|i)(1-p(x|i))
\end{equation}
\]&lt;/span>&lt;/p>
&lt;p>There is only a single way in which the staircase decreases intensity: the participant must provide two positive responses in a row. The probability of the intensity decreasing away from &lt;span class="math inline">\(i\)&lt;/span>, &lt;span class="math inline">\(p(\text{down|i})\)&lt;/span> is equal to the probability of two positive responses to that stimulus, or&lt;/p>
&lt;p>&lt;span class="math display">\[
\begin{equation}
p(\text{down|i}) = p(x|i)^2
\end{equation}
\]&lt;/span>&lt;/p>
&lt;p>Combining equations (1) and (2) will give a relationship that determines the proportion of positive responses participants will tend to provide under this staircase. To see how to combine these equations, remember that the one-up, one-down staircase converged on an intensity for which the proportion of positive and negative responses were equal. This equality occurred because at that intensity, the probability of an up and down step were equally likely. So, to determine at which intensity the one-up, two-down staircase converges, we must determine the probability of a positive response that will make an up and down step likely in the one-up, two-down staircase. That is, we set the right hand sides of equations (1) and (2) to be equal, and solve for &lt;span class="math inline">\(p(x|i)\)&lt;/span>&lt;a href="#fn1" class="footnote-ref" id="fnref1">&lt;sup>1&lt;/sup>&lt;/a>.&lt;/p>
&lt;p>&lt;span class="math display">\[
\begin{equation}
\begin{aligned}
p(x|i)(1-p(x|i)) + (1-p(x|i)) &amp;amp; = p(x|i)^2 \\
\implies p(x|i) - p(x|i)^2 + 1-p(x|i) &amp;amp; = p(x|i)^2 \\
\implies -2 p(x|i)^2 &amp;amp; = -1 \\
\implies p(x|i)&amp;amp; = \frac{1}{\sqrt{2}} \\
&amp;amp; \approx 0.707
\end{aligned}
\end{equation}
\]&lt;/span>&lt;/p>
&lt;p>Equation (3) shows that a one-up, two-down staircase will converge on a stimulus intensity that elicits approximately 70% positive responses (Figure &lt;a href="#fig:staircase">1&lt;/a>). As one way to see that this solution makes sense, relate this solution back to the probabilities of making either an up or down step. By equation (2), this solution implies that at this intensity, that an up step occurs with a 50% probability. As desired, any sequence that elicits a transition has an equal chance of being one that elicits either an up or down step.&lt;/p>
&lt;p>The original staircase procedure capitalized on the idea that the stimulus intensity which elicits half positive responses can be estimated by starting from an arbitrary intensity, changing the intensity on every trial based on whether a participant responded positively or negatively, and then retroactively looking at which intensities were shown. The transformed staircase enables estimation of an intensity that elicits different behavior. Similar algebra to that outlined in this post can be used to determine the proportion of positive responses elicited by other staircases. Unfortunately, most proportions will not have an easy staircase regime. Moreover, complex staircases will only change the stimulus intensity infrequently, requiring more trials to estimate the converged upon intensity stably. However, the proportions reachable by simple staircase are often good enough; rare is the experiment that requires, not 70.7% but 73% positive responses. And the staircase procedure did not require any knowledge of the exact shape of the psychometric function, just that there was a psychometric function. The simplicity of the transformed staircase makes it an attractive way to pick an intensity.&lt;/p>
&lt;div class="figure">&lt;span id="fig:staircase">&lt;/span>
&lt;img src="https://psadil.github.io/psadil/post/staircases-for-thresholds-part2/index_files/figure-html/staircase-1.png" alt="A sequence of trials with stimulus intensity governed by a one-up, two-down staircase. With this staircase, the intensity increases after a single negative response but decreases only after two positive responses. After enough trials, the average of the stimulus intensities shown to participants will elicit approximately 70% positive responses (dashed line). The intensity resulting from a one-up, one-down staircase is shown for comparison (solid line)." width="672" />
&lt;p class="caption">
Figure 1: A sequence of trials with stimulus intensity governed by a one-up, two-down staircase. With this staircase, the intensity increases after a single negative response but decreases only after two positive responses. After enough trials, the average of the stimulus intensities shown to participants will elicit approximately 70% positive responses (dashed line). The intensity resulting from a one-up, one-down staircase is shown for comparison (solid line).
&lt;/p>
&lt;/div>
&lt;div id="references" class="section level1 unnumbered">
&lt;h1>References&lt;/h1>
&lt;div id="refs" class="references csl-bib-body hanging-indent">
&lt;div id="ref-levitt1997" class="csl-entry">
Levitt, H. 1971. &lt;span>“Transformed up-down Methods in Psychoacoustics.”&lt;/span> &lt;em>The Journal of the Acoustical Society of America&lt;/em> 49 (2B): 467–77.
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="footnotes">
&lt;hr />
&lt;ol>
&lt;li id="fn1">&lt;p>The equation will have two solutions, but one of those solutions will be negative. A negative value is not an actual solution, because we are dealing with probabilities and so there is an additional constraint that &lt;span class="math inline">\(0 \leq p(x|i) \leq 1\)&lt;/span>&lt;a href="#fnref1" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Staircases for Thresholds</title><link>https://psadil.github.io/psadil/post/staircases-for-thresholds/</link><pubDate>Wed, 30 Oct 2019 00:00:00 +0000</pubDate><guid>https://psadil.github.io/psadil/post/staircases-for-thresholds/</guid><description>
&lt;script src="https://psadil.github.io/psadil/post/staircases-for-thresholds/index_files/header-attrs/header-attrs.js">&lt;/script>
&lt;p>Performing any experiment on cognition requires deciding which stimuli to use. Some experiments require participants to make many errors, requiring the stimuli to be challenging. In other experiments, participants must respond accurately, requiring stimuli that are easy but not so easy that participants lose attention. Moreover, participants behave idiosyncratically, so to avoid wasting either the researchers’ or participants’ time the stimuli ought to be tailored to each participant. To decide which stimuli to use, researchers can rely on a psychometric function (Figure &lt;a href="#fig:psychometric">1&lt;/a>). These functions describe a relationship between the intensity of a stimulus and how a participant responds to that stimulus, when responses can be classified as either a positive or negative. Precisely what is meant by ‘intensity’ and ‘positive or negative’ depends on the experimental task, but they roughly correspond to the amount of stimulation on each trial and how difficult it is to notice that stimulation. In a task in which participants must detect a pure tone that is occasionally presented over white noise, the intensity could be the volume of the tone and participants’ responses are positive when they detect the tone. With a psychometric function, deciding on a stimulus translates to picking the proportion of trials that should receive positive responses – picking the desired difficulty – and then using the intensity that elicits that behavior. This replaces the task of picking stimuli with inferring participants’ psychometric functions.&lt;/p>
&lt;div class="figure">&lt;span id="fig:psychometric">&lt;/span>
&lt;img src="https://psadil.github.io/psadil/post/staircases-for-thresholds/index_files/figure-html/psychometric-1.png" alt="A psychometric curve with threshold intensity. Psychometric curves relate the intensity of stimulation to the perception of stimulation, or the proportion positive responses. There are many parameterizations of these functions, but they are typically sigmoidal. The intensity at which, on average, half of responses are positive is often of interest. This intensity is called the threshold." width="672" />
&lt;p class="caption">
Figure 1: A psychometric curve with threshold intensity. Psychometric curves relate the intensity of stimulation to the perception of stimulation, or the proportion positive responses. There are many parameterizations of these functions, but they are typically sigmoidal. The intensity at which, on average, half of responses are positive is often of interest. This intensity is called the threshold.
&lt;/p>
&lt;/div>
&lt;p>To infer psychometric functions, standard procedures exist, though these procedures have varied efficiency. In particular, when only a single stimulus intensity is required, it would be inefficient to estimate the entire function. Consider a researcher attempting to elicit half positive responses, behavior elicited by the so called threshold stimulus intensity. A simple procedure to infer the psychometric function involves presenting a wide range of stimulus intensities, fitting the function to the data, and using the estimated function to infer the threshold. Each datum increases the precision of the estimate, but some data will be more useful than others. Intensities close to the tails of the function will pin down the function at those tails, but functions with different thresholds can behave similarly in their tails (Figure &lt;a href="#fig:psychometric2">2&lt;/a>). The threshold is most tightly constrained by responses to stimuli at the threshold &lt;span class="citation">(&lt;a href="#ref-levitt1997" role="doc-biblioref">Levitt 1971&lt;/a>)&lt;/span>. Therefore, an ideal procedure to estimate the threshold intensity would involve repeatedly presenting the threshold intensity. The ideal procedure is unfeasible, since if the threshold were known there would be no need for inference. But although the exact threshold intensity cannot be presented on every trial, certain procedures enable most trials to approximate the ideal.&lt;/p>
&lt;div class="figure">&lt;span id="fig:psychometric2">&lt;/span>
&lt;img src="https://psadil.github.io/psadil/post/staircases-for-thresholds/index_files/figure-html/psychometric2-1.png" alt="Psychometric functions with different thresholds. Although behavior at the tails of these functions are similar, they have different thresholds." width="672" />
&lt;p class="caption">
Figure 2: Psychometric functions with different thresholds. Although behavior at the tails of these functions are similar, they have different thresholds.
&lt;/p>
&lt;/div>
&lt;p>One type of procedure that locates the threshold intensity, both simply and efficiently, is called a staircase. A staircase procedure changes the stimulus intensity on every trial based on how participants respond. A staircase that locates the threshold increases stimulus intensity after a participant makes a negative response and decreases the intensity after a participant responds positively. Even when the first stimulus has an intensity far from the threshold (Figure &lt;a href="#fig:staircase">3&lt;/a>), the staircase brings the intensity to the threshold, a convergence that is ensured by the psychometric function. For example, when intensity is lower than the threshold, a participant tends to make negative responses. After a negative response, the contrast is increased. With an increased contrast, the participant will be more likely to make a positive response. If the intensity is still lower then then threshold, the participant will likely provide another negative response, causing the intensity increase further. After enough trials with intensity too low, the intensity will be pushed towards the threshold. If the intensity strays from the threshold, the same dynamics push the threshold back to threshold. The staircase forces the intensity to remain close to the threshold.&lt;/p>
&lt;div class="figure">&lt;span id="fig:staircase">&lt;/span>
&lt;img src="https://psadil.github.io/psadil/post/staircases-for-thresholds/index_files/figure-html/staircase-1.png" alt="Example sequence of trials in which stimulus intensity is controlled by a staircase procedure. After each negative response, the intensity increases, and after each positive response the intensity decreases. Although the initial intensity was much lower than the threshold, the staircase brings the intensity close to threshold and then keeps it there." width="672" />
&lt;p class="caption">
Figure 3: Example sequence of trials in which stimulus intensity is controlled by a staircase procedure. After each negative response, the intensity increases, and after each positive response the intensity decreases. Although the initial intensity was much lower than the threshold, the staircase brings the intensity close to threshold and then keeps it there.
&lt;/p>
&lt;/div>
&lt;div id="references" class="section level1 unnumbered">
&lt;h1>References&lt;/h1>
&lt;div id="refs" class="references csl-bib-body hanging-indent">
&lt;div id="ref-levitt1997" class="csl-entry">
Levitt, H. 1971. &lt;span>“Transformed up-down Methods in Psychoacoustics.”&lt;/span> &lt;em>The Journal of the Acoustical Society of America&lt;/em> 49 (2B): 467–77.
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Modulations to tuning functions can bias evidence accumulation</title><link>https://psadil.github.io/psadil/post/neural-modulation-for-serial-dependence/</link><pubDate>Fri, 18 Oct 2019 00:00:00 +0000</pubDate><guid>https://psadil.github.io/psadil/post/neural-modulation-for-serial-dependence/</guid><description>
&lt;script src="https://psadil.github.io/psadil/post/neural-modulation-for-serial-dependence/index_files/header-attrs/header-attrs.js">&lt;/script>
&lt;p>Perceptual decisions can be deconstructed with evidence accumulation models. These models formalize expectations about how participants behave, when that behavior involves repeatedly sampling information towards until surpassing a necessary threshold of information. At a cognitive level, the different models instantiate the components differently, but at a neural level the models rely on common mechanisms. To accumulate evidence the models assume two distinct populations of neurons. One population responds to available information. This population can be thought of as a sensory population, such that each neuron in the population represents one of the available options. The second population listens to the first, transforming the sensory activity into evidence for each decision and accumulating the evidence through time. This second population can be called an integrating population. While the location of the sensory population depends on the information that needs to be represented, the location of the integrating population depends on the required behavior. If participants must make decisions about orientations, the sensory population might be striatal neurons tuned to different orientations. If participants make decisions with saccades, the integrating population might be in the frontal eye fields. Understanding how these two populations reveals different ways that decisions can be biased.&lt;/p>
&lt;div class="figure">&lt;span id="fig:readout">&lt;/span>
&lt;img src="https://psadil.github.io/psadil/post/neural-modulation-for-serial-dependence/index_files/figure-html/readout-1.png" alt="Sensory channels evenly represent orientations. The curves from the sensory population represent the average activity of each neuron to a given orientation. Although the curves show average activity, at any given moment the actual activity of each neuron may be higher or lower. The integrating curve reflects the average evidence that the integrating population will record. The flatness of the integrating curve reflects an unbiased representation. Only eight neurons from the sensory population are shown to avoid overcrowding." width="672" />
&lt;p class="caption">
Figure 1: Sensory channels evenly represent orientations. The curves from the sensory population represent the average activity of each neuron to a given orientation. Although the curves show average activity, at any given moment the actual activity of each neuron may be higher or lower. The integrating curve reflects the average evidence that the integrating population will record. The flatness of the integrating curve reflects an unbiased representation. Only eight neurons from the sensory population are shown to avoid overcrowding.
&lt;/p>
&lt;/div>
&lt;p>For the integrating population to accumulate evidence, it must transform the activity of the sensory population into a meaningful signal. Figure &lt;a href="#fig:readout">1&lt;/a> depicts that transformation when participants must report orientations. Each neuron in the sensory population responds most strongly to a specific orientation, but all of them are active whenever an orientation is present. The function describing how a sensory neuron respond to different orientations is called the neuron’s tuning function. The integrating population will respond according to some other function of that sensory activity. One simple integrating function associates each neuron with its preferred orientation; the integrating population then tallies evidence based on whichever neuron is most active. This function requires the sensory population to represent each orientation with at least one neuron. If there are enough sensory neurons, the integrating population will be able to accumulate evidence for each orientation without bias.&lt;/p>
&lt;div class="figure">&lt;span id="fig:modulations">&lt;/span>
&lt;img src="https://psadil.github.io/psadil/post/neural-modulation-for-serial-dependence/index_files/figure-html/modulations-1.png" alt="Modulations to activity of the sensory population will provide the integrating population a biased representation of the orientation. Unlike in Figure 1, the sensory population in both panels provides the integrating population with an uneven representation of orientation." width="672" />
&lt;p class="caption">
Figure 2: Modulations to activity of the sensory population will provide the integrating population a biased representation of the orientation. Unlike in Figure 1, the sensory population in both panels provides the integrating population with an uneven representation of orientation.
&lt;/p>
&lt;/div>
&lt;p>The tuning characteristics of sensory neurons are variable, and this variability causes biases to emerge in the evidence accumulation process (Figure &lt;a href="#fig:modulations">2&lt;/a>). One common alteration is an increased gain, whereby the tuning function is multiplied by some value. When the gains of tuning functions are altered heterogeneously, a neuron may have a higher activity even when the orientation it is responsible for is not present. The neurons with the highest gain will bias the evidence gathered by the integrating population. Alternatively, tuning functions might shift, along with the orientation each neuron signals. The shift causes the sensory population to over-represent of some orientations and leave others underrepresented. These alterations can provide advantages in certain circumstances. For example, a heterogeneously increased gain will be useful when some orientations are known to be more likely than others, and a shift will be useful when different orientations require differently precise responses. But to accumulate evidence without bias, the sensory population must restore more uniform tuning.&lt;/p></description></item><item><title>serial dependence reflects a preference for low variability</title><link>https://psadil.github.io/psadil/post/serial-dependence-reflects-a-preference-for-low-variability/</link><pubDate>Fri, 11 Oct 2019 00:00:00 +0000</pubDate><guid>https://psadil.github.io/psadil/post/serial-dependence-reflects-a-preference-for-low-variability/</guid><description>
&lt;script src="https://psadil.github.io/psadil/post/serial-dependence-reflects-a-preference-for-low-variability/index_files/header-attrs/header-attrs.js">&lt;/script>
&lt;p>One framework for understanding perception casts it as inference: just as a statistician uncovers noisy data to uncover patterns, an organism perceives when it converts sensations into guesses about its environment. The framework not concrete enough to be called a theory of perception, since it is not clear what data could falsify it&lt;a href="#fn1" class="footnote-ref" id="fnref1">&lt;sup>1&lt;/sup>&lt;/a>. But the framework can remind perceptual researchers about the many strategies available for modeling the world. Do perceiving organisms employ similar strategies?&lt;/p>
&lt;p>One property that distinguishes many statistical strategies is a tradeoff between bias and variability Consider this tradeoff with an example. A statistician must estimate the average height of college-level soccer players. The true average could be uncovered by measuring the height of every player at every college–the statistician would not need inference. But the statistician is constrained by limited resources. They can only measure the players from a single college, though they may measure the heights of any student at the college. The statistician must now decide between an unbiased but variable or biased but precise strategy. Measuring only the soccer players gives an unbiased estimate, but with so few players the team’s average may be far from the true average. The statistician cannot be confident that the single team resembles all teams. Alternatively, the statistician may supplement their estimate with the heights of players from another, related sport. Since ultimate frisbee players may have similar heights to soccer players, incorporating their heights into the estimate may counteract any anomalously sized soccer players. However, incorporating even a single player from another sport biases the estimate, in the sense that the average height of all soccer players will not equal the average height of all soccer players and the one ultimate player&lt;a href="#fn2" class="footnote-ref" id="fnref2">&lt;sup>2&lt;/sup>&lt;/a>. One strategy – measure only soccer players – would give the true answer if there were enough resources, but the other strategy – measure everyone that is similar to a soccer player – may approximate the truth well with limited resources.&lt;/p>
&lt;p>The bias-variability tradeoff gives a functional interpretation to the perceptual effect called serial dependence &lt;span class="citation">(&lt;a href="#ref-fischer2014" role="doc-biblioref">Fischer and Whitney 2014&lt;/a>; &lt;a href="#ref-cicchini2018" role="doc-biblioref">Cicchini, Mikellidou, and Burr 2018&lt;/a>)&lt;/span>. Serial dependence occurs when participants judge perceptual stimuli across many trials, and their judgments on one trial depend on their immediately preceding judgment. Like the constrained statistician, participants may not process each stimulus completely: participants only see stimuli for brief durations, their judgments are made after the stimuli are masked, and their attention fluctuates throughout the hundreds of trials. The bias is often attractive, meaning that participants’ judgments reflect a blending of the stimuli on the current and previous trials. Serial dependence may reflect a strategy – not necessarily intentional – that reduces variability across judgments by combining information. Although the strategy biases the judgments, it may help each individual estimate approach truth.&lt;/p>
&lt;div id="references" class="section level1 unnumbered">
&lt;h1>References&lt;/h1>
&lt;div id="refs" class="references csl-bib-body hanging-indent">
&lt;div id="ref-cicchini2018" class="csl-entry">
Cicchini, G. M., K. Mikellidou, and D. C Burr. 2018. &lt;span>“The Functional Role of Serial Dependence.”&lt;/span> &lt;em>Proceedings of the Royal Society B&lt;/em> 285 (1890): 20181722.
&lt;/div>
&lt;div id="ref-fischer2014" class="csl-entry">
Fischer, Jason, and David Whitney. 2014. &lt;span>“Serial Dependence in Visual Perception.”&lt;/span> &lt;em>Nature Neuroscience&lt;/em> 17 (5): 738.
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="footnotes">
&lt;hr />
&lt;ol>
&lt;li id="fn1">&lt;p>A perceptual system does need to be limited to the statistical tools that have already been developed, so even a demonstration that organisms don’t employ any known statistical tool would not rule out the framework.&lt;a href="#fnref1" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn2">&lt;p>Assume that the ultimate player is not as tall as the average soccer player&lt;a href="#fnref2" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>derivative of gaussian for serial dependence</title><link>https://psadil.github.io/psadil/post/derivative-of-gaussian-for-serial-dependence/</link><pubDate>Thu, 03 Oct 2019 00:00:00 +0000</pubDate><guid>https://psadil.github.io/psadil/post/derivative-of-gaussian-for-serial-dependence/</guid><description>
&lt;script src="https://psadil.github.io/psadil/post/derivative-of-gaussian-for-serial-dependence/index_files/header-attrs/header-attrs.js">&lt;/script>
&lt;p>Cognitive experiments can require participants to complete hundreds of trials, but completing so many trials invariably alters participants’ behavior. Their behavior late in the experiment can depend on their behavior early in the experiment. Although such dependence can be an experimental confound,
the dependence itself can provide clues about cognition. One simple kind of dependence occurs through learning; hundreds of trials provides participants ample practice. A more subtle dependence can emerge between sequential trials, an effect called serial dependence. Theoretical interpretations of serial dependence vary, and some of that variability may relate to how the dependence is measured. In this post, I review a statistical method commonly used to analyze serial dependence and discuss one way that method can fail.&lt;/p>
&lt;p>I will focus on the analysis of an orientation judgment task, in which participants simply see an oriented bar on each trial, remember the bar’s orientation for a short period, and then report the orientation. Participants’ responses on one trial can depend on the orientation they saw in the previous trial. The dependence follows a Gaussian’s derivative function. Figure &lt;a href="#fig:dog0">1&lt;/a>A shows a Gaussian function with its derivative, and Figure &lt;a href="#fig:dog0">1&lt;/a>B shows the derivative modeling a range of different serial dependence patterns. The derivative captures three key features of the data. First, different changes in orientation between trials result in serial dependencies of different magnitude. The responsiveness of dependence is captured by the width of the derivative. Second, serial dependence can have a different magnitude. The magnitude is captured by the amplitude of the derivative. Finally, responses on the current trial can either be attracted towards or repulsed away from the orientation of the previous trial. The direction of the effect is captured with the sign of the amplitude. The direction of the effect–and the experimental manipulations that change that direction–are often critical to different theoretical interpretations of serial dependence.&lt;/p>
&lt;div class="figure">&lt;span id="fig:dog0">&lt;/span>
&lt;img src="https://psadil.github.io/psadil/post/derivative-of-gaussian-for-serial-dependence/index_files/figure-html/dog0-1.png" alt="A) A Gaussian function and its derivative. B) The derivative captures how errors on the current trial can depend on how the relationship between the orientation seen in the current and previous trials. Positive values on the horizontal axis signify a clockwise difference and negative values a counterclockwise difference. Likewise, positive errors signify responses on the current trial which were clockwise to the true orientation, and negative errors are counterclockwise. When errors are in the same direction as the difference in orientations, the error is said to be attractive. Otherwise, the error is repulsive. Whether errors are attractive or repulsive is given by the sign of the derivative's amplitude." width="672" />
&lt;p class="caption">
Figure 1: A) A Gaussian function and its derivative. B) The derivative captures how errors on the current trial can depend on how the relationship between the orientation seen in the current and previous trials. Positive values on the horizontal axis signify a clockwise difference and negative values a counterclockwise difference. Likewise, positive errors signify responses on the current trial which were clockwise to the true orientation, and negative errors are counterclockwise. When errors are in the same direction as the difference in orientations, the error is said to be attractive. Otherwise, the error is repulsive. Whether errors are attractive or repulsive is given by the sign of the derivative’s amplitude.
&lt;/p>
&lt;/div>
&lt;p>Although the Gaussian’s derivative adequately models the serial dependence between trials with similar orientations (less than 45 degree differences), the derivative fits poorly the dependencies following large changes. When sequential trials have a large orientation difference, the sign of the dependence often changes; small orientation differences can elicit an attractive dependence even while large differences are repulsive. These sign flips are called the peripheral bumps, and they are not captured by the Gaussian’s derivative. If the bumps are large enough, they can interpretations about the sign to of dependencies following small changes can be inverted (Figure &lt;a href="#fig:bumps">2&lt;/a>). Unfortunately, noticing the peripheral bumps can be hard with sparse data. But even with sparse data, the width of the best-fitting derivative can help identify bumps. If the best-fitting derivative is abnormally wide (with peaks larger than approximately 35 degrees), then the derivative is tracking dependencies wider than it should. In that circumstance, it may be best to focus analyses on only the trials with smaller orientation differences.&lt;/p>
&lt;div class="figure">&lt;span id="fig:bumps">&lt;/span>
&lt;img src="https://psadil.github.io/psadil/post/derivative-of-gaussian-for-serial-dependence/index_files/figure-html/bumps-1.png" alt="Misfits of the Gaussian's derivative. The dots give hypothetical data. The data were generated with a function whose average is traced by the dashed line. The data were fit with a derivative of Guassian function, and the best-fitting derivative is shown with a solid line. The derivative does not match the data-generating function." width="672" />
&lt;p class="caption">
Figure 2: Misfits of the Gaussian’s derivative. The dots give hypothetical data. The data were generated with a function whose average is traced by the dashed line. The data were fit with a derivative of Guassian function, and the best-fitting derivative is shown with a solid line. The derivative does not match the data-generating function.
&lt;/p>
&lt;/div></description></item><item><title>an overview of population receptive field mapping</title><link>https://psadil.github.io/psadil/post/population-receptive-field-mapping/</link><pubDate>Fri, 27 Sep 2019 00:00:00 +0000</pubDate><guid>https://psadil.github.io/psadil/post/population-receptive-field-mapping/</guid><description>
&lt;script src="https://psadil.github.io/psadil/post/population-receptive-field-mapping/index.en_files/header-attrs/header-attrs.js">&lt;/script>
&lt;p>Perceiving the world requires representing the world in neural tissue. A neuron is &lt;em>tuned&lt;/em> to perceivable information when different values of that information cause the neuron to fire at a different rate. For example, most visual neurons are tuned to spatial location. The spatial tuning could be measured by placing a recording electrode in a neuron in a macaque’s visual cortex while the macaque fixated on the center of a computer monitor and a picture moved across that monitor. The electrode would report higher activity only when the picture was in certain parts of the macaque’s visual field. The function relating the position of the picture to the neuron’s activity is the tuning function. Such functions often resembles a bivariate Gaussian (Figure &lt;a href="#fig:prf">1&lt;/a>). To study these tuning functions is to study how these neurons represent the world.&lt;/p>
&lt;div class="figure">&lt;span id="fig:prf">&lt;/span>
&lt;img src="https://psadil.github.io/psadil/post/population-receptive-field-mapping/index.en_files/figure-html/prf-1.png" alt="The bivariate Gaussian represents a neuron's receptive field. The neuron will be most responsive to information that overlaps with the bright yellow regions. Since this the upper left portion of the box is slightly encompassed by the receptive field, the neuron' might fire slightly more rapidly as compared to its baseline rate." width="672" />
&lt;p class="caption">
Figure 1: The bivariate Gaussian represents a neuron’s receptive field. The neuron will be most responsive to information that overlaps with the bright yellow regions. Since this the upper left portion of the box is slightly encompassed by the receptive field, the neuron’ might fire slightly more rapidly as compared to its baseline rate.
&lt;/p>
&lt;/div>
&lt;p>Sensory neurons are tuned to many other features such as orientation, color, pitch, direction of motion. Most neurons tuned to one visual feature are also tuned to spatial location, so understanding a neuron’s spatial can facilitate understanding its other sensitivities&lt;a href="#fn1" class="footnote-ref" id="fnref1">&lt;sup>1&lt;/sup>&lt;/a>. The tuning functions of neurons even have a special name, their receptive field. However, it is often unfeasible to record from individual neurons in humans, and instead only non-invasive neuroimaging methods are available. But these non-invasive methods have low spatial resolution. Even the relatively well spatially resolved technique of functional magnetic resonance imaging reflects the aggregated activity of 10e5 - 10e6 neurons.&lt;/p>
&lt;p>Fortunately, the &lt;em>retinotopic&lt;/em> arrangement of visual neurons facilitates relating the spatial tuning of a voxel&lt;a href="#fn2" class="footnote-ref" id="fnref2">&lt;sup>2&lt;/sup>&lt;/a> to the receptive field of individual neurons. A retinotopic arrangement means that neighboring neurons are tuned to neighboring locations in the visual field; for example, neurons tuned to things in the fovea cluster together and neurons tuned to peripheral locations surround that cluster. This retinotopic arrangement implies that all neurons sampled by a voxel represent nearby regions in the visual environment. Referring to the neurons in a voxel as a population, the receptive field of a voxel is called a population receptive field. Studying population receptive fields alone cannot reveal how individual neurons contribute to a coherent perceptual experience, but studying them can reveal how the populations respond as a group.&lt;/p>
&lt;p>To chart out all of the mountainous population receptive fields in visual cortex is called population receptive field mapping &lt;span class="citation">(&lt;a href="#ref-dumoulin2008" role="doc-biblioref">Dumoulin and Wandell 2008&lt;/a>)&lt;/span>. The receptive fields can be mapped by recording the activity of each voxel while a human participant is shown some visually salient movie. A mathematical model – such as a bivariate Gaussian – of the receptive field is assumed, and the data from each voxel are used to fit the parameters of that model. The specific images that are used will depend on which part of visual cortex is the focus of the experiment. A counterphasing black and white checkerboard might be close to optimal for primary visual cortex, but the checkerboard would only weakly stimulate neurons in higher level visual regions. To stimulate most of visual cortex, other researchers rely on &lt;a href="https://kendrickkay.net/analyzePRF/">more varied displays&lt;/a>.&lt;/p>
&lt;div id="references" class="section level1 unnumbered">
&lt;h1>References&lt;/h1>
&lt;div id="refs" class="references csl-bib-body hanging-indent">
&lt;div id="ref-dumoulin2008" class="csl-entry">
Dumoulin, Serge O, and Brian A Wandell. 2008. &lt;span>“Population Receptive Field Estimates in Human Visual Cortex.”&lt;/span> &lt;em>Neuroimage&lt;/em> 39 (2): 647–60.
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="footnotes">
&lt;hr />
&lt;ol>
&lt;li id="fn1">&lt;p>e.g., if you want to understand how a neuron is tuned to color, it helps to know where to put the color&lt;a href="#fnref1" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn2">&lt;p> &lt;em>Voxels&lt;/em> are the elements that hold data in magnetic resonance imaging. A voxel in a 3D image is analogous to a pixel in a 2D image; a voxel is a pixel with a volume.&lt;a href="#fnref2" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Serial Dependence</title><link>https://psadil.github.io/psadil/post/serial-dependence/</link><pubDate>Thu, 19 Sep 2019 00:00:00 +0000</pubDate><guid>https://psadil.github.io/psadil/post/serial-dependence/</guid><description>
&lt;script src="https://psadil.github.io/psadil/post/serial-dependence/index.en_files/header-attrs/header-attrs.js">&lt;/script>
&lt;p>Objects in the visual environment move suddenly and erratically, and visual perception must be sensitive to the changes that are important. But each saccade and head tilt change the image imprinted on the retina, and to perceive every tremor ignores the stability of the visual environment; a desk will still look like a desk in a few seconds. The visual system must therefore balance the ability to detect subtle changes in the environment against the efficiency afforded by accurate predictions.&lt;/p>
&lt;p>That the recent past influences current perception can be demonstrated easily. If you stare at Figure &lt;a href="#fig:tae">1&lt;/a>, you might observe that the Gabor has a bend immediately after changing orientations. The bend lasts for a moment, then straightens. But the bend is an illusion. While tracking Figure &lt;a href="#fig:tae">1&lt;/a>, the visual system allows for a momentary bias. Usefully, the bias is sensitive to experimental manipulation. Figure &lt;a href="#fig:tae2">2&lt;/a> shows the same Gabor with the same orientations, but the Gabor also moves. The movement largely eliminates the bending. The sensitivity of such biases to different experimental manipulations enables researchers to study how the visual system balances new information against the recent past.&lt;/p>
&lt;div class="figure">&lt;span id="fig:tae">&lt;/span>
&lt;img src="https://psadil.github.io/psadil/post/serial-dependence/index.en_files/figure-html/tae-1.gif" alt="A Gabor alternates between two orientations." />
&lt;p class="caption">
Figure 1: A Gabor alternates between two orientations.
&lt;/p>
&lt;/div>
&lt;div class="figure">&lt;span id="fig:tae2">&lt;/span>
&lt;img src="https://psadil.github.io/psadil/post/serial-dependence/index.en_files/figure-html/tae2-1.gif" alt="A Gabor alternates between two orientations, appearing in a different location with each orientation." />
&lt;p class="caption">
Figure 2: A Gabor alternates between two orientations, appearing in a different location with each orientation.
&lt;/p>
&lt;/div>
&lt;p>A closely effect is called &lt;em>serial dependence&lt;/em>. Serial dependence occurs when participants report the orientations of sequentially presented, tilted Gabors &lt;span class="citation">(&lt;a href="#ref-fischer2014" role="doc-biblioref">Fischer and Whitney 2014&lt;/a>)&lt;/span>. A visual mask to reduces the strong aftereffects present in Figures &lt;a href="#fig:tae">1&lt;/a> and &lt;a href="#fig:tae2">2&lt;/a> [Figure &lt;a href="#fig:gabor">3&lt;/a>]&lt;a href="#fn1" class="footnote-ref" id="fnref1">&lt;sup>1&lt;/sup>&lt;/a>. Even without the aftereffect, the perceptual-decision about one Gabor affects the perceptual-decision about the next; participants report orientations that consistently err toward the orientation of the most recently seen Gabor. Reports on the magnitude of the effect vary, but the error has an average maximum of less than a few degrees. However, serial dependence is affected by different manipulations than that the demonstration of Figures &lt;a href="#fig:tae">1&lt;/a> and &lt;a href="#fig:tae2">2&lt;/a>. For example, it appears insensitive to the location of the Gabors. This bias may therefore provide a unique way to study how current perception is not only biased by but toward the recent past.&lt;/p>
&lt;div class="figure">&lt;span id="fig:gabor">&lt;/span>
&lt;img src="https://psadil.github.io/psadil/post/serial-dependence/index.en_files/figure-html/gabor-1.gif" alt="Differently oriented Gabors presented with interspersed noise masks.." />
&lt;p class="caption">
Figure 3: Differently oriented Gabors presented with interspersed noise masks..
&lt;/p>
&lt;/div>
&lt;p>However, it remains unclear whether serial dependence is a bias of perceptual or post-perceptual processes. That is, does serial dependence alter participants’ perception of the Gabors, or does it alter how they report the orientation? The sequential timing of each trial – in which participants respond in a designated period after seeing the Gabor – does not imply that participants decide on an orientation only after they have finished perceiving the Gabor. For example, a participant can make decisions before the response period, and they can adopt a biased response strategy even before seeing the Gabor. Where and when to delineate between perception and decision, or whether they can be delineated, depends on assumptions about the relationship between perception and decisions. A tool like the &lt;a href="https://psadil.github.io/psadil/post/circular-diffusion-model-of-response-times/">circular diffusion model&lt;/a> can help make those assumptions explicit &lt;span class="citation">(&lt;a href="#ref-smith2016" role="doc-biblioref">Smith 2016&lt;/a>)&lt;/span>.&lt;/p>
&lt;div id="references" class="section level1 unnumbered">
&lt;h1>References&lt;/h1>
&lt;div id="refs" class="references csl-bib-body hanging-indent">
&lt;div id="ref-fischer2014" class="csl-entry">
Fischer, Jason, and David Whitney. 2014. &lt;span>“Serial Dependence in Visual Perception.”&lt;/span> &lt;em>Nature Neuroscience&lt;/em> 17 (5): 738.
&lt;/div>
&lt;div id="ref-smith2016" class="csl-entry">
Smith, Philip L. 2016. &lt;span>“Diffusion Theory of Decision Making in Continuous Report.”&lt;/span> &lt;em>Psychological Review&lt;/em> 123 (4): 425–51. &lt;a href="https://doi.org/10.1037/rev0000023">https://doi.org/10.1037/rev0000023&lt;/a>.
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="footnotes">
&lt;hr />
&lt;ol>
&lt;li id="fn1">&lt;p>The timing and spacing of this figure does not quite match a typical experiment. For example, participants take a few seconds to respond, so the amount of time between Gabors in this figure is too short.&lt;a href="#fnref1" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div></description></item></channel></rss>