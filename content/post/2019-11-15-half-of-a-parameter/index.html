---
title: Half of a parameter
author: Patrick Sadil
date: '2019-11-15'
slug: half-of-a-parameter
categories:
  - dissertation
tags: []
image:
  caption: ''
  focal_point: ''
link-citations: true
bibliography: [2019-11-15-half-of-a-parameter.bib]
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>


<p>Science produces models that provide parsimonious descriptions of the world. In cognitive psychology, models regularly compete to explain a few phenomena. But models can survive experiment after experiment, both because of the difficulty of capturing participant’s nuanced behavior, and because models often make highly overlapping predictions. In these cases, a model succeeds through its relative parsimony.</p>
<p>In cognitive psychology, measures of information criteria, specifically Akaike’s and the Bayesian information criteria <span class="citation">(<a href="#ref-schwarz1978" role="doc-biblioref">Schwarz 1978</a>; <a href="#ref-akaike1998" role="doc-biblioref">Akaike 1973</a>)</span>, determine a winning model. These criteria measure complexity by tallying the number of parameters in a model. Long maths and specific assumptions justify the claim that a model with more parameters is more complex than a model with fewer parameters, and so does our intuition that a model is complex if it has many moving parts. Unfortunately, the assumptions fail in common situations, such as when the models are fit in a Bayesian rather than frequentist setting. An alphabet soup of other information criteria exists (in addition to Akaike’s the Bayesian criteria, there is the DIC, WAIC, KIC, NIC, TIC, etc), and these other criteria assign complexity more complexly. These criteria are sensitive not only to the number of parameters in a model but also to the varied roles that a parameter can have. They assign the complexity of a model based on the model’s number of ‘effective parameters.’</p>
<p>For intuition on why tallying the number of parameters is an insufficient measure complexity, consider two models of response time. Both models assume that response times are distributed according to a normal distribution. In this simple example, the variability of the distributions are known, and so the models have only a single free parameter, which is the average response time. In one model, that average can be any number, a value from negative to positive infinity. This is the kind of model implicitly assumed when we conduct a t-test on the averages of response times. Of course the model is a simplification of response times, but this model also has the glaring flaw that it allows the average response time to be negative; a participant cannot respond to stimulation before the stimulus appears. The second model addresses this flaw by adding the constraint that the average response time cannot be negative. Although the second model is more constrained, the models have the same number of parameters. The second model can only account for half of the patterns of data as the first; the second model is twice as parsimonious as the first <span class="citation">(<a href="#ref-gelman2014" role="doc-biblioref">Gelman, Hwang, and Vehtari 2014</a>)</span>. To adjudicate between these model requires a measure that is sensitive to complexity but does not simply tally the number of parameters in each model.</p>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-akaike1998" class="csl-entry">
Akaike, Hirotogu. 1973. <span>“Information Theory and an Extension of the Maximum Likelihood Principle.”</span> In <em>Proceedings of the Second International Symposium on Information Theory</em>, 267–81.
</div>
<div id="ref-gelman2014" class="csl-entry">
Gelman, Andrew, Jessica Hwang, and Aki Vehtari. 2014. <span>“Understanding Predictive Information Criteria for <span>Bayesian</span> Models.”</span> <em>Statistics and Computing</em> 24 (6): 997–1016. <a href="https://doi.org/10.1007/s11222-013-9416-2">https://doi.org/10.1007/s11222-013-9416-2</a>.
</div>
<div id="ref-schwarz1978" class="csl-entry">
Schwarz, Gideon. 1978. <span>“Estimating the Dimension of a Model.”</span> <em>The Annals of Statistics</em> 6 (2): 461–64. <a href="https://doi.org/10.1214/aos/1176344136">https://doi.org/10.1214/aos/1176344136</a>.
</div>
</div>
</div>
