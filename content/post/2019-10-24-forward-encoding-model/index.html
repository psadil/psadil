---
title: Forward encoding model
author: Patrick Sadil
date: '2019-10-24'
slug: forward-encoding-model
categories: []
tags:
  - fmri
image:
  caption: ''
  focal_point: ''
link-citations: true
bibliography: [2019-10-24-forward-encoding-model.bib]
math: true
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>


<p>Functional magnetic resonance imaging records brain activity with spatially distinct voxels, but this segmentation will be misaligned with a brain’s meaningful boundaries. The segmentation results in some voxels recording activity from different types of tissue – types that are both neural an non-neural – but even voxels that exclusively sample gray matter can span functionally distinct cortex. For example, a 3T scanner allows voxels in the range of 1.5-3 mm<span class="math inline">\(^3\)</span>, but orientation columns have an average width of 0.8 mm <span class="citation">(<a href="#ref-yacoub2008" role="doc-biblioref">Yacoub, Harel, and Uğurbil 2008</a>)</span>. Studying orientation columns with such low resolution requires statistical tools.</p>
<p>One statistical tool models voxel activity as a linear combination of the activity of a small number of neural channels <span class="citation">(<a href="#ref-brouwer2009" role="doc-biblioref">Brouwer and Heeger 2009</a>; <a href="#ref-kay2008" role="doc-biblioref">Kay et al. 2008</a>)</span>. These models are called forward models, describing how the channel activity transforms into voxel activity. In early sensory cortex, the channels are analogous to cortical columns. In later cortex, the channels are more abstract dimensions of a representational space. Developing a forward model requires assuming not only how many channels contribute of a voxel’s activity, but also the tuning properties of those channels. With these assumptions, regression allows inferring the contribution of each channel to each voxel’s activity. Let <span class="math inline">\(N\)</span> be the number of observations for each voxel, <span class="math inline">\(M\)</span> be the number of voxels, and <span class="math inline">\(K\)</span> be the number of channels within a voxel. The forward model specifies that the data (<span class="math inline">\(B\)</span>, <span class="math inline">\(M \times N\)</span>) result from a weighted combination of the assumed channels responses (<span class="math inline">\(C\)</span>, <span class="math inline">\(K \times N\)</span>), where the weights (<span class="math inline">\(W\)</span>, <span class="math inline">\(M \times K\)</span>) are unknown.</p>
<p><span class="math display">\[
B = WC
\]</span></p>
<p>Taking the pseudoinverse of the channel matrix and multiplying the result by the data gives an estimate of the weight matrix:</p>
<p><span class="math display">\[
\widehat{W} = BC^T(CC^T)^{-1}
\]</span></p>
<p>Assumptions about <span class="math inline">\(C\)</span> are assumptions about how the channels encode stimuli. Different encoding schemes can be instantiated with different <span class="math inline">\(C\)</span>, and any method for comparing linear models could be used to compare the schemes.</p>
<p>The forward encoding model enables comparison of static encoding schemes, but neural encoding schemes are dynamic. Attentional fluctuations, perceptual learning, and stimulation history all modulate neural tuning functions <span class="citation">(<a href="#ref-mcadams1999" role="doc-biblioref">McAdams and Maunsell 1999</a>; <a href="#ref-reynolds2000" role="doc-biblioref">Reynolds, Pasternak, and Desimone 2000</a>; <a href="#ref-siegel2015" role="doc-biblioref">Siegel, Buschman, and Miller 2015</a>; <a href="#ref-yang2004" role="doc-biblioref">Yang and Maunsell 2004</a>)</span>. To explore modulations with functional magnetic resonance imaging, some researchers have inverted the encoding model <span class="citation">(<a href="#ref-garcia2013" role="doc-biblioref">Garcia, Srinivasan, and Serences 2013</a>; <a href="#ref-rahmati2018" role="doc-biblioref">Rahmati, Saber, and Curtis 2018</a>; <a href="#ref-saproo2014" role="doc-biblioref">Saproo and Serences 2014</a>; <a href="#ref-scolari2012" role="doc-biblioref">Scolari, Byers, and Serences 2012</a>; <a href="#ref-sprague2013" role="doc-biblioref">Sprague and Serences 2013</a>; <a href="#ref-vo2017" role="doc-biblioref">Vo, Sprague, and Serences 2017</a>)</span>. The inversion is a variation of cross validation. The method estimates the weight matrix with only some of the data (e.g., all data excluding a single run). The held out data, <span class="math inline">\(B_H\)</span>, contains observations from all experimental condition across which the tuning functions might vary. The encoding model is inverted by multiplying the pseudoinverse of the weight matrix with the held out data to estimate a new channel response matrix.</p>
<p><span class="math display">\[
\widehat{C} = \widehat{W}^T(\widehat{W}\widehat{W}^T)^{-1}B_H
\]</span></p>
<p>The new channel response matrix estimates how the channels respond in each experimental condition.</p>
<p>Although validation studies demonstrated that the inverted encoding model enables inferences that recapitulate some modulations observed with electrophysiology <span class="citation">(<a href="#ref-sprague2018" role="doc-biblioref">Sprague et al. 2018</a>; <a href="#ref-sprague2015" role="doc-biblioref">Sprague, Saproo, and Serences 2015</a>)</span>, the inversion also misleads inferences about certain fundamental modulations <span class="citation">(<a href="#ref-gardner2019" role="doc-biblioref">Gardner and Liu 2019</a>; <a href="#ref-liu2018" role="doc-biblioref">Liu, Cable, and Gardner 2018</a>)</span>. In particular, increasing the contrast of an orientation increases the gain of neurons tuned to orientation without altering their tuning bandwidth <span class="citation">(<a href="#ref-alitto2004" role="doc-biblioref">Alitto and Usrey 2004</a>; <a href="#ref-sclar1982" role="doc-biblioref">Sclar and Freeman 1982</a>; <a href="#ref-skottun1987" role="doc-biblioref">Skottun et al. 1987</a>)</span>, but the inverted encoding model (incorrectly) suggests that higher contrast decreases bandwidth <span class="citation">(<a href="#ref-liu2018" role="doc-biblioref">Liu, Cable, and Gardner 2018</a>)</span>. Inferences are misled because the estimated channel responses are constrained by the initial assumptions about <span class="math inline">\(C\)</span> <span class="citation">(<a href="#ref-gardner2019" role="doc-biblioref">Gardner and Liu 2019</a>)</span>. Using the encoding model to study modulations requires a way to estimate the contribution of each channel without assuming a fixed channel response function.</p>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-alitto2004" class="csl-entry">
Alitto, Henry J, and W Martin Usrey. 2004. <span>“Influence of Contrast on Orientation and Temporal Frequency Tuning in Ferret Primary Visual Cortex.”</span> <em>Journal of Neurophysiology</em> 91 (6): 2797–2808.
</div>
<div id="ref-brouwer2009" class="csl-entry">
Brouwer, Gijs Joost, and David J Heeger. 2009. <span>“Decoding and Reconstructing Color from Responses in Human Visual Cortex.”</span> <em>Journal of Neuroscience</em> 29 (44): 13992–4003.
</div>
<div id="ref-garcia2013" class="csl-entry">
Garcia, Javier O, Ramesh Srinivasan, and John T Serences. 2013. <span>“Near-Real-Time Feature-Selective Modulations in Human Cortex.”</span> <em>Current Biology</em> 23 (6): 515–22.
</div>
<div id="ref-gardner2019" class="csl-entry">
Gardner, Justin L, and Taosheng Liu. 2019. <span>“Inverted Encoding Models Reconstruct an Arbitrary Model Response, Not the Stimulus.”</span> <em>eNeuro</em> 6 (2).
</div>
<div id="ref-kay2008" class="csl-entry">
Kay, Kendrick N, Thomas Naselaris, Ryan J Prenger, and Jack L Gallant. 2008. <span>“Identifying Natural Images from Human Brain Activity.”</span> <em>Nature</em> 452 (7185): 352.
</div>
<div id="ref-liu2018" class="csl-entry">
Liu, Taosheng, Dylan Cable, and Justin L Gardner. 2018. <span>“Inverted Encoding Models of Human Population Response Conflate Noise and Neural Tuning Width.”</span> <em>Journal of Neuroscience</em> 38 (2): 398–408.
</div>
<div id="ref-mcadams1999" class="csl-entry">
McAdams, Carrie J, and John HR Maunsell. 1999. <span>“Effects of Attention on Orientation-Tuning Functions of Single Neurons in Macaque Cortical Area V4.”</span> <em>Journal of Neuroscience</em> 19 (1): 431–41.
</div>
<div id="ref-rahmati2018" class="csl-entry">
Rahmati, Masih, Golbarg T Saber, and Clayton E Curtis. 2018. <span>“Population Dynamics of Early Visual Cortex During Working Memory.”</span> <em>Journal of Cognitive Neuroscience</em> 30 (2): 219–33.
</div>
<div id="ref-reynolds2000" class="csl-entry">
Reynolds, John H, Tatiana Pasternak, and Robert Desimone. 2000. <span>“Attention Increases Sensitivity of V4 Neurons.”</span> <em>Neuron</em> 26 (3): 703–14.
</div>
<div id="ref-saproo2014" class="csl-entry">
Saproo, Sameer, and John T Serences. 2014. <span>“Attention Improves Transfer of Motion Information Between V1 and MT.”</span> <em>Journal of Neuroscience</em> 34 (10): 3586–96.
</div>
<div id="ref-sclar1982" class="csl-entry">
Sclar, G, and RD Freeman. 1982. <span>“Orientation Selectivity in the Cat’s Striate Cortex Is Invariant with Stimulus Contrast.”</span> <em>Experimental Brain Research</em> 46 (3): 457–61.
</div>
<div id="ref-scolari2012" class="csl-entry">
Scolari, Miranda, Anna Byers, and John T Serences. 2012. <span>“Optimal Deployment of Attentional Gain During Fine Discriminations.”</span> <em>Journal of Neuroscience</em> 32 (22): 7723–33.
</div>
<div id="ref-siegel2015" class="csl-entry">
Siegel, Markus, Timothy J Buschman, and Earl K Miller. 2015. <span>“Cortical Information Flow During Flexible Sensorimotor Decisions.”</span> <em>Science</em> 348 (6241): 1352–55.
</div>
<div id="ref-skottun1987" class="csl-entry">
Skottun, Bernt C, Arthur Bradley, Gary Sclar, Izumi Ohzawa, and Ralph D Freeman. 1987. <span>“The Effects of Contrast on Visual Orientation and Spatial Frequency Discrimination: A Comparison of Single Cells and Behavior.”</span> <em>Journal of Neurophysiology</em> 57 (3): 773–86.
</div>
<div id="ref-sprague2018" class="csl-entry">
Sprague, Thomas C, Kirsten CS Adam, Joshua J Foster, Masih Rahmati, David W Sutterer, and Vy A Vo. 2018. <span>“Inverted Encoding Models Assay Population-Level Stimulus Representations, Not Single-Unit Neural Tuning.”</span> <em>eNeuro</em> 5 (3).
</div>
<div id="ref-sprague2015" class="csl-entry">
Sprague, Thomas C, Sameer Saproo, and John T Serences. 2015. <span>“Visual Attention Mitigates Information Loss in Small-and Large-Scale Neural Codes.”</span> <em>Trends in Cognitive Sciences</em> 19 (4): 215–26.
</div>
<div id="ref-sprague2013" class="csl-entry">
Sprague, Thomas C, and John T Serences. 2013. <span>“Attention Modulates Spatial Priority Maps in the Human Occipital, Parietal and Frontal Cortices.”</span> <em>Nature Neuroscience</em> 16 (12): 1879.
</div>
<div id="ref-vo2017" class="csl-entry">
Vo, Vy A, Thomas C Sprague, and John T Serences. 2017. <span>“Spatial Tuning Shifts Increase the Discriminability and Fidelity of Population Codes in Visual Cortex.”</span> <em>Journal of Neuroscience</em> 37 (12): 3386–3401.
</div>
<div id="ref-yacoub2008" class="csl-entry">
Yacoub, Essa, Noam Harel, and Kâmil Uğurbil. 2008. <span>“High-Field fMRI Unveils Orientation Columns in Humans.”</span> <em>Proceedings of the National Academy of Sciences</em> 105 (30): 10607–12.
</div>
<div id="ref-yang2004" class="csl-entry">
Yang, Tianming, and John HR Maunsell. 2004. <span>“The Effect of Perceptual Learning on Neuronal Responses in Monkey Visual Area V4.”</span> <em>Journal of Neuroscience</em> 24 (7): 1617–26.
</div>
</div>
</div>
