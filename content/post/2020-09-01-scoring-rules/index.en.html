---
title: scoring rules
author: Patrick Sadil
date: '2020-09-01'
slug: []
categories: []
tags: []
subtitle: ''
summary: ''
authors: []
lastmod: '2020-09-01T20:52:35-04:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
draft: true
---

<script src="{{< blogdown/postref >}}index.en_files/header-attrs/header-attrs.js"></script>


<p>Bayes’ Rule gives that <span class="math inline">\(p(\theta|y) \propto p(\theta) p(y|\theta)\)</span>, that the posterior distribution, <span class="math inline">\(p(\theta|y)\)</span> of the parameters, <span class="math inline">\(\theta\)</span>, is proportional to a prior distribution on those parameters, <span class="math inline">\(p(\theta)\)</span>, multiplied by the likelihood of the data, <span class="math inline">\(p(y|\theta)\)</span>. The rule specifies a procedure for using observed data, <span class="math inline">\(y\)</span>, to learn about the parameters, but it does not give a procedure for making decisions based on those parameters. In this dissertation, the statistical decisions are based primarily on the ability of different models to predict new data, <span class="math inline">\(\tilde{y}\)</span>, as approximated by PSIS-LOO+. However, this approach is relatively rare in cognitive psychology. The notation closely follows that of <span class="citation">[@vehtari_practical_2017]</span>.</p>
<p>Currently in Psychology, the strategy is to rely on Bayes’ Factors. There are a few different ways to view Bayes’ Factors. I’m going to question whether Bayes’ Factors are actually a good way to choose a new model.</p>
<p>There are a few different ways to motivate Bayes’ factors. One simple strategy comes from an application of Bayes’ rule. If we have a model, <span class="math inline">\(M\)</span>, we can ask a question like: what is the probability of a model, given that we’ve observed data? This gives the relationship</p>
<p><span class="math display">\[
p(M|y) = \frac{p(y|M)p(M)}{p(y)}
\]</span></p>
<p>This relationship is not, by itself, particularly helpful. There is approximately 0 chance that we’ve specified exactly the right model, so any calculation that allowed <span class="math inline">\(p(M|y) &gt; 0\)</span> should immediately be suspect. But if we have two models, <span class="math inline">\(M_0\)</span> and <span class="math inline">\(M_1\)</span>, it makes a bit of sense to talk about the relative probability of each model.</p>
<p><span class="math display">\[
\frac{p(M_1|y)}{p(M_0|y)} = \underbrace{\frac{p(y|M_1)}{p(y|M_0)}}_{\text{Bayes Factor}} \frac{p(M_1)}{p(M_0)}
\]</span></p>
<p>Assuming that the prior probability associated with each model are equal, then this ratio of posterior is driven entirely by the ratio of likelihoods of the data under each of the different models. However, it is again questionable whether this relationship practical makes sense to calculate. As before, I have no faith that the models I’ve specified are literally the truth, so for me <span class="math inline">\(p(M_0)\)</span> is 0. Just because these are the two models I’m currently willing to entertain does not mean that I think they are actually true (after all, <em>all</em> models are wrong…).</p>
<p>But let’s assume that we’re talking about some small world, where all statements are qualified with the assumption that one of these two models are true.</p>
<p>Now we step into a tricky part of language. It is common to talk about a model’s ‘predictions’ in reference to how well the model can capture the already observed data. This language leads some authors to talk about Bayes’ factor as a measure of the (relative) ‘predictive accuracy’ of a model.</p>
<p>By the chain rule, the implied predictions can also be viewed sequentially [waiting on book to see whether this is relevant]</p>
<p><span class="math display">\[
p(y|M) = p(y_1|M)p(y_2|M,y_1)\ldots p(y_n | M,y_1,y_2,\ldots,y_{n-1})
\]</span></p>
<p>:A distribution indicating what new data are likely under a posterior distribution. <span class="math inline">\(p(\tilde{y}_i | y) = \int p(\tilde{y}_i|\theta)p(\theta | y) d \theta\)</span>. Note that the distribution is for a single new observation, <span class="math inline">\(\tilde{y}_i\)</span>.</p>
<p>: Expected log, pointwise predictive density. This is an expectation of the log score of the posterior predictive distribution for each observation, summed across all observations in a dataset: $_{i=1}^{n} p_t(_i)(_i | y ) d _i $. The distribution <span class="math inline">\(p_t(\tilde{y}_i)\)</span> is the true (unknown) data-generating distribution for observation <span class="math inline">\(\tilde{y}_i\)</span> . Roughly, the ELPD measures the predictive ability of a model by first scoring how likely a model “thinks” a particular observation will be (through the log of the posterior predictive distribution), then weighting that score by the probability of observing that observation (through the true, data generating distribution), and finally combining these weighted scores across all possible values of each observation and all observations in a dataset (the integration and summation).</p>
