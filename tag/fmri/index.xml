<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>fmri | psadil</title><link>https://psadil.github.io/psadil/tag/fmri/</link><atom:link href="https://psadil.github.io/psadil/tag/fmri/index.xml" rel="self" type="application/rss+xml"/><description>fmri</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2023 Patrick Sadil</copyright><lastBuildDate>Sat, 14 Mar 2020 00:00:00 +0000</lastBuildDate><image><url>https://psadil.github.io/psadil/media/icon_hu3896c2ce465988ba1fc8077f9a6388c6_268630_512x512_fill_lanczos_center_2.png</url><title>fmri</title><link>https://psadil.github.io/psadil/tag/fmri/</link></image><item><title>counterbalanced continuous designs with eulerian walks</title><link>https://psadil.github.io/psadil/post/counterbalanced-continuous-designs-with-eulerian-walks/</link><pubDate>Sat, 14 Mar 2020 00:00:00 +0000</pubDate><guid>https://psadil.github.io/psadil/post/counterbalanced-continuous-designs-with-eulerian-walks/</guid><description>
&lt;script src="https://psadil.github.io/psadil/post/counterbalanced-continuous-designs-with-eulerian-walks/index.en_files/header-attrs/header-attrs.js">&lt;/script>
&lt;script src="https://psadil.github.io/psadil/post/counterbalanced-continuous-designs-with-eulerian-walks/index.en_files/htmlwidgets/htmlwidgets.js">&lt;/script>
&lt;script src="https://psadil.github.io/psadil/post/counterbalanced-continuous-designs-with-eulerian-walks/index.en_files/viz/viz.js">&lt;/script>
&lt;link href="https://psadil.github.io/psadil/post/counterbalanced-continuous-designs-with-eulerian-walks/index.en_files/DiagrammeR-styles/styles.css" rel="stylesheet" />
&lt;script src="https://psadil.github.io/psadil/post/counterbalanced-continuous-designs-with-eulerian-walks/index.en_files/grViz-binding/grViz.js">&lt;/script>
&lt;p>Many experiments require counterbalancing sequences of trials. For example, I’m currently running an experiment on &lt;a href="https://psadil.github.io/psadil/post/serial-dependence/">serial dependence&lt;/a>&lt;a href="#fn1" class="footnote-ref" id="fnref1">&lt;sup>1&lt;/sup>&lt;/a>. In my experiment, participants report the orientation of a grating&lt;a href="#fn2" class="footnote-ref" id="fnref2">&lt;sup>2&lt;/sup>&lt;/a> stimulus on each trial. The serial dependence effect is how their responses on one trial depend on either the orientation of the previous trial or their response on that trial. To tease apart the effects of prior stimuli from prior responses, I’m manipulating the visual contrast of the gratings ( &lt;a href="https://en.wikipedia.org/wiki/Contrast_(vision)#Michelson_contrast">Michelson contrast&lt;/a> ). There are three levels of contrast: high, low, and zero (at zero contrast, there is no grating stimulus). This experiment will only need a few of the eight possible pairs of contrasts, and I’d like a sequence of trials that does not have any filler trials. So I need a flexible way to generate sequences of contrast.&lt;/p>
&lt;p>It turns out that this problem can be formulated as constructing an &lt;a href="https://en.wikipedia.org/wiki/Eulerian_path">Eulerian, directed cycle&lt;/a>. There are likely other ways &lt;a href="#fn3" class="footnote-ref" id="fnref3">&lt;sup>3&lt;/sup>&lt;/a>, but I think this is a neat approach. I won’t talk much about why any of this works, primarily because I don’t feel qualified to do so. However, the post includes a script that implements the algorithm, and checks that it has worked. So, hopefully it’ll be useful to at least a future me. But before discussing an Eulerian circuit, let’s talk about formulating the stimulus conditions as a graph.&lt;/p>
&lt;div id="trials-can-be-represented-with-a-graph" class="section level1">
&lt;h1>Trials can be represented with a graph&lt;/h1>
&lt;p>All potential sequences of trials will be represented as a graph. The graphs nodes will correspond to conditions, and edges between the nodes will correspond to allowable transitions. To represent these graphs, I’ll use the &lt;a href="http://visualizers.co/diagrammer/">&lt;code>DiagrammeR&lt;/code> package&lt;/a>.&lt;/p>
&lt;pre class="r">&lt;code># library(DiagrammeR)
library(magrittr)
# library(dplyr)&lt;/code>&lt;/pre>
&lt;p>In the graph of my experiment, there will be three nodes for each of the three conditions (Figure &lt;a href="#fig:nodes">1&lt;/a>).&lt;/p>
&lt;pre class="r">&lt;code>nodes &amp;lt;- DiagrammeR::create_node_df(
n = 3,
label = c(&amp;quot;zero&amp;quot;,&amp;quot;low&amp;quot;,&amp;quot;high&amp;quot;))
DiagrammeR::create_graph(nodes_df = nodes) %&amp;gt;%
DiagrammeR::render_graph(layout = &amp;quot;tree&amp;quot;)&lt;/code>&lt;/pre>
&lt;div class="figure">&lt;span id="fig:nodes">&lt;/span>
&lt;div id="htmlwidget-1" style="width:672px;height:480px;" class="grViz html-widget">&lt;/div>
&lt;script type="application/json" data-for="htmlwidget-1">{"x":{"diagram":"digraph {\n\ngraph [layout = \"neato\",\n outputorder = \"edgesfirst\",\n bgcolor = \"white\"]\n\nnode [fontname = \"Helvetica\",\n fontsize = \"10\",\n shape = \"circle\",\n fixedsize = \"true\",\n width = \"0.5\",\n style = \"filled\",\n fillcolor = \"aliceblue\",\n color = \"gray70\",\n fontcolor = \"gray50\"]\n\nedge [fontname = \"Helvetica\",\n fontsize = \"8\",\n len = \"1.5\",\n color = \"gray80\",\n arrowsize = \"0.5\"]\n\n \"1\" [label = \"zero\", fillcolor = \"#F0F8FF\", fontcolor = \"#000000\", pos = \"0,1!\"] \n \"2\" [label = \"low\", fillcolor = \"#F0F8FF\", fontcolor = \"#000000\", pos = \"1,1!\"] \n \"3\" [label = \"high\", fillcolor = \"#F0F8FF\", fontcolor = \"#000000\", pos = \"2,1!\"] \n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}&lt;/script>
&lt;p class="caption">
Figure 1: Node represent experimental conditions.
&lt;/p>
&lt;/div>
&lt;p>In my experiment, I want trials to go from low to high, zero to high, or high to high, high to low, and high to zero (Figure &lt;a href="#fig:edges">2&lt;/a>). Including only these five types of transitions means excluding a few of the possible edges that could be in the graph. For example, I do not want any zero contrast trials to follow any other zero contrast trials, nor do I want a low contrast trial to follow a zero contrast trial.&lt;/p>
&lt;pre class="r">&lt;code>edges &amp;lt;- DiagrammeR::create_edge_df(
from = c(1,2,3,3,3),
to = c(3,3,3,1,2))
DiagrammeR::create_graph(
nodes_df = nodes,
edges_df = edges) %&amp;gt;%
DiagrammeR::render_graph(
layout = &amp;quot;tree&amp;quot;)&lt;/code>&lt;/pre>
&lt;div class="figure">&lt;span id="fig:edges">&lt;/span>
&lt;div id="htmlwidget-2" style="width:672px;height:480px;" class="grViz html-widget">&lt;/div>
&lt;script type="application/json" data-for="htmlwidget-2">{"x":{"diagram":"digraph {\n\ngraph [layout = \"neato\",\n outputorder = \"edgesfirst\",\n bgcolor = \"white\"]\n\nnode [fontname = \"Helvetica\",\n fontsize = \"10\",\n shape = \"circle\",\n fixedsize = \"true\",\n width = \"0.5\",\n style = \"filled\",\n fillcolor = \"aliceblue\",\n color = \"gray70\",\n fontcolor = \"gray50\"]\n\nedge [fontname = \"Helvetica\",\n fontsize = \"8\",\n len = \"1.5\",\n color = \"gray80\",\n arrowsize = \"0.5\"]\n\n \"1\" [label = \"zero\", fillcolor = \"#F0F8FF\", fontcolor = \"#000000\", pos = \"0,2!\"] \n \"2\" [label = \"low\", fillcolor = \"#F0F8FF\", fontcolor = \"#000000\", pos = \"1,2!\"] \n \"3\" [label = \"high\", fillcolor = \"#F0F8FF\", fontcolor = \"#000000\", pos = \"0.5,1!\"] \n \"1\"->\"3\" \n \"2\"->\"3\" \n \"3\"->\"3\" \n \"3\"->\"1\" \n \"3\"->\"2\" \n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}&lt;/script>
&lt;p class="caption">
Figure 2: Directed edges between nodes represent allowable transitions.
&lt;/p>
&lt;/div>
&lt;p>Constructing a sequence of trials will correspond to walking along the edges, from node to node. That walk will be Eulerian if each edge is be visited exactly once. With so few edges, it’s easy enough to visualize an Eulerian walk through the edges. One possible Eulerian walk (a cycle&lt;a href="#fn4" class="footnote-ref" id="fnref4">&lt;sup>4&lt;/sup>&lt;/a>, even) is shown in Figure &lt;a href="#fig:smallwalk">3&lt;/a>.&lt;/p>
&lt;pre class="r">&lt;code>edges_labelled &amp;lt;- DiagrammeR::create_edge_df(
from = c(3,2,3,3,1),
to = c(2,3,3,1,3),
label = as.character(1:5))
DiagrammeR::create_graph(
nodes_df = nodes,
edges_df = edges_labelled) %&amp;gt;%
DiagrammeR::render_graph(
layout = &amp;quot;tree&amp;quot;)&lt;/code>&lt;/pre>
&lt;div class="figure">&lt;span id="fig:smallwalk">&lt;/span>
&lt;div id="htmlwidget-3" style="width:672px;height:480px;" class="grViz html-widget">&lt;/div>
&lt;script type="application/json" data-for="htmlwidget-3">{"x":{"diagram":"digraph {\n\ngraph [layout = \"neato\",\n outputorder = \"edgesfirst\",\n bgcolor = \"white\"]\n\nnode [fontname = \"Helvetica\",\n fontsize = \"10\",\n shape = \"circle\",\n fixedsize = \"true\",\n width = \"0.5\",\n style = \"filled\",\n fillcolor = \"aliceblue\",\n color = \"gray70\",\n fontcolor = \"gray50\"]\n\nedge [fontname = \"Helvetica\",\n fontsize = \"8\",\n len = \"1.5\",\n color = \"gray80\",\n arrowsize = \"0.5\"]\n\n \"1\" [label = \"zero\", fillcolor = \"#F0F8FF\", fontcolor = \"#000000\", pos = \"0,2!\"] \n \"2\" [label = \"low\", fillcolor = \"#F0F8FF\", fontcolor = \"#000000\", pos = \"1,2!\"] \n \"3\" [label = \"high\", fillcolor = \"#F0F8FF\", fontcolor = \"#000000\", pos = \"0.5,1!\"] \n\"3\"->\"2\" [label = \"1\"] \n\"2\"->\"3\" [label = \"2\"] \n\"3\"->\"3\" [label = \"3\"] \n\"3\"->\"1\" [label = \"4\"] \n\"1\"->\"3\" [label = \"5\"] \n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}&lt;/script>
&lt;p class="caption">
Figure 3: The numbers trace an Eulerian cycle on this graph.
&lt;/p>
&lt;/div>
&lt;p>The cycle in Figure &lt;a href="#fig:smallwalk">3&lt;/a> implies a workable sequence of six trials, but the use of this Eulerian conceptualization will be how it automates creating much longer sequences. For example, to achieve 21 trials the edges could be replicated four times. Figure &lt;a href="#fig:messy">4&lt;/a> shows the graph with replicated edges, and already it looks too messy to traverse by sight. A real experiment will involve hundreds of trials, meaning that we’d like a way to automatically traverse an Eulerian circuit.&lt;/p>
&lt;pre class="r">&lt;code>edges_messy &amp;lt;- DiagrammeR::create_edge_df(
from = rep(c(3,2,3,3,1), each=4),
to = rep(c(2,3,3,1,3), each=4))
DiagrammeR::create_graph(
nodes_df = nodes,
edges_df = edges_messy) %&amp;gt;%
DiagrammeR::render_graph(layout = &amp;quot;tree&amp;quot;)&lt;/code>&lt;/pre>
&lt;div class="figure">&lt;span id="fig:messy">&lt;/span>
&lt;div id="htmlwidget-4" style="width:672px;height:480px;" class="grViz html-widget">&lt;/div>
&lt;script type="application/json" data-for="htmlwidget-4">{"x":{"diagram":"digraph {\n\ngraph [layout = \"neato\",\n outputorder = \"edgesfirst\",\n bgcolor = \"white\"]\n\nnode [fontname = \"Helvetica\",\n fontsize = \"10\",\n shape = \"circle\",\n fixedsize = \"true\",\n width = \"0.5\",\n style = \"filled\",\n fillcolor = \"aliceblue\",\n color = \"gray70\",\n fontcolor = \"gray50\"]\n\nedge [fontname = \"Helvetica\",\n fontsize = \"8\",\n len = \"1.5\",\n color = \"gray80\",\n arrowsize = \"0.5\"]\n\n \"1\" [label = \"zero\", fillcolor = \"#F0F8FF\", fontcolor = \"#000000\", pos = \"0,2!\"] \n \"2\" [label = \"low\", fillcolor = \"#F0F8FF\", fontcolor = \"#000000\", pos = \"1,2!\"] \n \"3\" [label = \"high\", fillcolor = \"#F0F8FF\", fontcolor = \"#000000\", pos = \"0.5,1!\"] \n \"3\"->\"2\" \n \"3\"->\"2\" \n \"3\"->\"2\" \n \"3\"->\"2\" \n \"2\"->\"3\" \n \"2\"->\"3\" \n \"2\"->\"3\" \n \"2\"->\"3\" \n \"3\"->\"3\" \n \"3\"->\"3\" \n \"3\"->\"3\" \n \"3\"->\"3\" \n \"3\"->\"1\" \n \"3\"->\"1\" \n \"3\"->\"1\" \n \"3\"->\"1\" \n \"1\"->\"3\" \n \"1\"->\"3\" \n \"1\"->\"3\" \n \"1\"->\"3\" \n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}&lt;/script>
&lt;p class="caption">
Figure 4: Replicating edges quickly complicates the graph.
&lt;/p>
&lt;/div>
&lt;/div>
&lt;div id="hierholzers-algorithm-automates-eulerian-cycles" class="section level1">
&lt;h1>Hierholzer’s algorithm automates Eulerian cycles&lt;/h1>
&lt;p>Fortunately, there exists and algorithm for making Eulerian cycles that is both simple to implement and quick to run. First, here is a helper function to replicate edges, &lt;code>replicate_edges&lt;/code>.&lt;/p>
&lt;pre class="r">&lt;code>#&amp;#39; replicate_edges
#&amp;#39;
#&amp;#39; @param edge_df output of DiagrammeR::create_edge_df (will only need columns `to` and `from`)
#&amp;#39; @param n_reps integer number of times that the edges should be replicated
#&amp;#39;
#&amp;#39; @return replicated edge dataframe
replicate_edges &amp;lt;- function(edge_df, n_reps){
replicate(n_reps, edge_df, simplify = FALSE) %&amp;gt;%
dplyr::bind_rows() %&amp;gt;%
dplyr::mutate(id = 1:dplyr::n())
}&lt;/code>&lt;/pre>
&lt;p>The next function will generate the Eulerian circuit, &lt;code>walk_circuit&lt;/code>. It will take in an edge dataframe (possibly replicated) and output a vector containing the nodes listed in the order that they were reached. Again, I won’t spend too long explaining why this works. But the basic idea is to traverse the edges, deleting edges as you walk along them. You’ll eventually reach a dead-end. If there are still more edges, then backtrack until you can travel along an edge that will result in a different dead-end. Save a list of the nodes that were traveled while backtracking, and these nodes will contain the circuit.&lt;/p>
&lt;pre class="r">&lt;code>#&amp;#39; walk_circuit
#&amp;#39;
#&amp;#39; @param edge_df edge dataframes
#&amp;#39; @param curr_v vertex at which to start the circuit
#&amp;#39;
#&amp;#39; @return vector consisting of Eulerian circuit along edges
#&amp;#39;
#&amp;#39; @details modified python script from https://gregorulm.com/finding-an-eulerian-path/.
walk_circuit &amp;lt;- function(edge_df, curr_v){
# helpful to have the edges stored by node
adj &amp;lt;- edge_df %&amp;gt;%
dplyr::group_split(from)
# vector to store final circuit
circuit &amp;lt;- c()
# Maintain a stack to keep vertices
# start from given node
curr_path &amp;lt;- curr_v
while (length(curr_path)){
# If there&amp;#39;s a remaining edge
if (nrow(adj[[curr_v]])){
# Push the vertex
curr_path &amp;lt;- c(curr_path,curr_v)
# Find the next vertex using an edge
next_v_ind &amp;lt;- sample.int(nrow(adj[[curr_v]]), size=1)
next_v &amp;lt;- adj[[curr_v]]$to[next_v_ind]
# and remove that edge
adj[[curr_v]] &amp;lt;- adj[[curr_v]][-next_v_ind,]
# Move to next vertex
curr_v &amp;lt;- next_v
} else{ # back-track to find remaining circuit
circuit &amp;lt;- c(circuit, curr_v)
# Back-tracking
curr_v &amp;lt;- tail(curr_path, n = 1)
curr_path &amp;lt;- head(curr_path, n = -1)
}
}
return(rev(circuit))
}&lt;/code>&lt;/pre>
&lt;p>Now replicate the edges twice and go for and Eulerian tour.&lt;/p>
&lt;pre class="r">&lt;code>edges_twice &amp;lt;- replicate_edges(edges, 2)
walk_circuit(edges_twice, 3)&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 3 1 3 2 3 1 3 3 2 3 3&lt;/code>&lt;/pre>
&lt;p>This sequence is small enough that it’s feasible to verify the Eulerian property by hand, but it’ll be nice to have automate the checking. That is the purpose of this next function, &lt;code>check_blocking&lt;/code>.&lt;/p>
&lt;pre class="r">&lt;code>#&amp;#39; check_blocking
#&amp;#39;
#&amp;#39; @param circuit output of walk_circuit
#&amp;#39; @param nodes nodes_df, output of DiagrammeR::create_node_df. Used to label which nodes were visited during the walk
#&amp;#39;
#&amp;#39; @return tbl containing the counts of each transition type contained in the circuit.
#&amp;#39; If all went well, the counts should be equal
check_blocking &amp;lt;- function(circuit, nodes){
tibble::tibble(contrast = circuit, .name_repair = &amp;quot;check_unique&amp;quot;) %&amp;gt;%
dplyr::mutate(
trial = 1:dplyr::n(),
contrast = nodes$label[contrast],
last_contrast = dplyr::lag(contrast)) %&amp;gt;%
dplyr::filter(trial &amp;gt; 1) %&amp;gt;%
dplyr::group_by(contrast, last_contrast) %&amp;gt;%
dplyr::summarise(n = dplyr::n(), .groups = &amp;quot;drop&amp;quot;)
}&lt;/code>&lt;/pre>
&lt;p>Now, generate a sequence of 101 trials,&lt;/p>
&lt;pre class="r">&lt;code>edges_large &amp;lt;- replicate_edges(edges, n_reps = 20)
circuit &amp;lt;- walk_circuit(edges_large, 3)
circuit&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 3 2 3 3 1 3 2 3 2 3 3 1 3 1 3 3 1 3 3 2 3 1 3 2 3 2 3 1 3 3 1 3 3 2 3 3 3
## [38] 1 3 1 3 1 3 3 2 3 2 3 3 2 3 2 3 1 3 1 3 3 2 3 1 3 1 3 3 2 3 1 3 3 3 3 3 2
## [75] 3 3 1 3 2 3 3 2 3 1 3 1 3 3 1 3 2 3 2 3 1 3 3 2 3 2 3&lt;/code>&lt;/pre>
&lt;p>and check that each transition happened equally often&lt;/p>
&lt;pre class="r">&lt;code>check_blocking(circuit, nodes) %&amp;gt;%
knitr::kable()&lt;/code>&lt;/pre>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th align="left">contrast&lt;/th>
&lt;th align="left">last_contrast&lt;/th>
&lt;th align="right">n&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td align="left">high&lt;/td>
&lt;td align="left">high&lt;/td>
&lt;td align="right">20&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="left">high&lt;/td>
&lt;td align="left">low&lt;/td>
&lt;td align="right">20&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td align="left">high&lt;/td>
&lt;td align="left">zero&lt;/td>
&lt;td align="right">20&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="left">low&lt;/td>
&lt;td align="left">high&lt;/td>
&lt;td align="right">20&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td align="left">zero&lt;/td>
&lt;td align="left">high&lt;/td>
&lt;td align="right">20&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/div>
&lt;div class="footnotes">
&lt;hr />
&lt;ol>
&lt;li id="fn1">&lt;p>Well, I was running. Out of precaution for COVID-19, it currently seems like a bad idea to try to collect more participants. And UMass is closed for the rest of the semester.&lt;a href="#fnref1" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn2">&lt;p>adjacent black and white lines cropped to a circle, where the transitions between luminance follows a sinusoid&lt;a href="#fnref2" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn3">&lt;p>In this particular case, a simpler solution would be to assign each pair of contrasts a number. For example,&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>high -&amp;gt; high&lt;/li>
&lt;li>low -&amp;gt; high&lt;/li>
&lt;li>zero -&amp;gt; high&lt;/li>
&lt;/ol>
&lt;p>An appropriate sequence could be generated by simply permuting the numbers. For example 2, 3, 1, 3, 2 In that case, the sequence of trials would be &lt;code>low high zero high high high zero high low high&lt;/code>. This works because the second trial of each of the transitions are &lt;code>high&lt;/code>. But what if you also wanted a few &lt;code>low-&amp;gt;low&lt;/code> and &lt;code>zero-&amp;gt;zero&lt;/code> transitions, but wanted neither &lt;code>low-&amp;gt;zero&lt;/code> nor &lt;code>zero-&amp;gt;low&lt;/code>? By simply permuting the number codes, a &lt;code>zero-&amp;gt;zero&lt;/code> transition could appear right after a &lt;code>low-&amp;gt;low&lt;/code> transition, but to do that would require a filler &lt;code>low-zero&lt;/code>.&lt;a href="#fnref3" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn4">&lt;p>a cycle or circuit is a walk that starts and ends at the same node&lt;a href="#fnref4" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Forward encoding model</title><link>https://psadil.github.io/psadil/post/forward-encoding-model/</link><pubDate>Thu, 24 Oct 2019 00:00:00 +0000</pubDate><guid>https://psadil.github.io/psadil/post/forward-encoding-model/</guid><description>
&lt;script src="https://psadil.github.io/psadil/post/forward-encoding-model/index_files/header-attrs/header-attrs.js">&lt;/script>
&lt;p>Functional magnetic resonance imaging records brain activity with spatially distinct voxels, but this segmentation will be misaligned with a brain’s meaningful boundaries. The segmentation results in some voxels recording activity from different types of tissue – types that are both neural an non-neural – but even voxels that exclusively sample gray matter can span functionally distinct cortex. For example, a 3T scanner allows voxels in the range of 1.5-3 mm&lt;span class="math inline">\(^3\)&lt;/span>, but orientation columns have an average width of 0.8 mm &lt;span class="citation">(&lt;a href="#ref-yacoub2008" role="doc-biblioref">Yacoub, Harel, and Uğurbil 2008&lt;/a>)&lt;/span>. Studying orientation columns with such low resolution requires statistical tools.&lt;/p>
&lt;p>One statistical tool models voxel activity as a linear combination of the activity of a small number of neural channels &lt;span class="citation">(&lt;a href="#ref-brouwer2009" role="doc-biblioref">Brouwer and Heeger 2009&lt;/a>; &lt;a href="#ref-kay2008" role="doc-biblioref">Kay et al. 2008&lt;/a>)&lt;/span>. These models are called forward models, describing how the channel activity transforms into voxel activity. In early sensory cortex, the channels are analogous to cortical columns. In later cortex, the channels are more abstract dimensions of a representational space. Developing a forward model requires assuming not only how many channels contribute of a voxel’s activity, but also the tuning properties of those channels. With these assumptions, regression allows inferring the contribution of each channel to each voxel’s activity. Let &lt;span class="math inline">\(N\)&lt;/span> be the number of observations for each voxel, &lt;span class="math inline">\(M\)&lt;/span> be the number of voxels, and &lt;span class="math inline">\(K\)&lt;/span> be the number of channels within a voxel. The forward model specifies that the data (&lt;span class="math inline">\(B\)&lt;/span>, &lt;span class="math inline">\(M \times N\)&lt;/span>) result from a weighted combination of the assumed channels responses (&lt;span class="math inline">\(C\)&lt;/span>, &lt;span class="math inline">\(K \times N\)&lt;/span>), where the weights (&lt;span class="math inline">\(W\)&lt;/span>, &lt;span class="math inline">\(M \times K\)&lt;/span>) are unknown.&lt;/p>
&lt;p>&lt;span class="math display">\[
B = WC
\]&lt;/span>&lt;/p>
&lt;p>Taking the pseudoinverse of the channel matrix and multiplying the result by the data gives an estimate of the weight matrix:&lt;/p>
&lt;p>&lt;span class="math display">\[
\widehat{W} = BC^T(CC^T)^{-1}
\]&lt;/span>&lt;/p>
&lt;p>Assumptions about &lt;span class="math inline">\(C\)&lt;/span> are assumptions about how the channels encode stimuli. Different encoding schemes can be instantiated with different &lt;span class="math inline">\(C\)&lt;/span>, and any method for comparing linear models could be used to compare the schemes.&lt;/p>
&lt;p>The forward encoding model enables comparison of static encoding schemes, but neural encoding schemes are dynamic. Attentional fluctuations, perceptual learning, and stimulation history all modulate neural tuning functions &lt;span class="citation">(&lt;a href="#ref-mcadams1999" role="doc-biblioref">McAdams and Maunsell 1999&lt;/a>; &lt;a href="#ref-reynolds2000" role="doc-biblioref">Reynolds, Pasternak, and Desimone 2000&lt;/a>; &lt;a href="#ref-siegel2015" role="doc-biblioref">Siegel, Buschman, and Miller 2015&lt;/a>; &lt;a href="#ref-yang2004" role="doc-biblioref">Yang and Maunsell 2004&lt;/a>)&lt;/span>. To explore modulations with functional magnetic resonance imaging, some researchers have inverted the encoding model &lt;span class="citation">(&lt;a href="#ref-garcia2013" role="doc-biblioref">Garcia, Srinivasan, and Serences 2013&lt;/a>; &lt;a href="#ref-rahmati2018" role="doc-biblioref">Rahmati, Saber, and Curtis 2018&lt;/a>; &lt;a href="#ref-saproo2014" role="doc-biblioref">Saproo and Serences 2014&lt;/a>; &lt;a href="#ref-scolari2012" role="doc-biblioref">Scolari, Byers, and Serences 2012&lt;/a>; &lt;a href="#ref-sprague2013" role="doc-biblioref">Sprague and Serences 2013&lt;/a>; &lt;a href="#ref-vo2017" role="doc-biblioref">Vo, Sprague, and Serences 2017&lt;/a>)&lt;/span>. The inversion is a variation of cross validation. The method estimates the weight matrix with only some of the data (e.g., all data excluding a single run). The held out data, &lt;span class="math inline">\(B_H\)&lt;/span>, contains observations from all experimental condition across which the tuning functions might vary. The encoding model is inverted by multiplying the pseudoinverse of the weight matrix with the held out data to estimate a new channel response matrix.&lt;/p>
&lt;p>&lt;span class="math display">\[
\widehat{C} = \widehat{W}^T(\widehat{W}\widehat{W}^T)^{-1}B_H
\]&lt;/span>&lt;/p>
&lt;p>The new channel response matrix estimates how the channels respond in each experimental condition.&lt;/p>
&lt;p>Although validation studies demonstrated that the inverted encoding model enables inferences that recapitulate some modulations observed with electrophysiology &lt;span class="citation">(&lt;a href="#ref-sprague2018" role="doc-biblioref">Sprague et al. 2018&lt;/a>; &lt;a href="#ref-sprague2015" role="doc-biblioref">Sprague, Saproo, and Serences 2015&lt;/a>)&lt;/span>, the inversion also misleads inferences about certain fundamental modulations &lt;span class="citation">(&lt;a href="#ref-gardner2019" role="doc-biblioref">Gardner and Liu 2019&lt;/a>; &lt;a href="#ref-liu2018" role="doc-biblioref">Liu, Cable, and Gardner 2018&lt;/a>)&lt;/span>. In particular, increasing the contrast of an orientation increases the gain of neurons tuned to orientation without altering their tuning bandwidth &lt;span class="citation">(&lt;a href="#ref-alitto2004" role="doc-biblioref">Alitto and Usrey 2004&lt;/a>; &lt;a href="#ref-sclar1982" role="doc-biblioref">Sclar and Freeman 1982&lt;/a>; &lt;a href="#ref-skottun1987" role="doc-biblioref">Skottun et al. 1987&lt;/a>)&lt;/span>, but the inverted encoding model (incorrectly) suggests that higher contrast decreases bandwidth &lt;span class="citation">(&lt;a href="#ref-liu2018" role="doc-biblioref">Liu, Cable, and Gardner 2018&lt;/a>)&lt;/span>. Inferences are misled because the estimated channel responses are constrained by the initial assumptions about &lt;span class="math inline">\(C\)&lt;/span> &lt;span class="citation">(&lt;a href="#ref-gardner2019" role="doc-biblioref">Gardner and Liu 2019&lt;/a>)&lt;/span>. Using the encoding model to study modulations requires a way to estimate the contribution of each channel without assuming a fixed channel response function.&lt;/p>
&lt;div id="references" class="section level1 unnumbered">
&lt;h1>References&lt;/h1>
&lt;div id="refs" class="references csl-bib-body hanging-indent">
&lt;div id="ref-alitto2004" class="csl-entry">
Alitto, Henry J, and W Martin Usrey. 2004. &lt;span>“Influence of Contrast on Orientation and Temporal Frequency Tuning in Ferret Primary Visual Cortex.”&lt;/span> &lt;em>Journal of Neurophysiology&lt;/em> 91 (6): 2797–2808.
&lt;/div>
&lt;div id="ref-brouwer2009" class="csl-entry">
Brouwer, Gijs Joost, and David J Heeger. 2009. &lt;span>“Decoding and Reconstructing Color from Responses in Human Visual Cortex.”&lt;/span> &lt;em>Journal of Neuroscience&lt;/em> 29 (44): 13992–4003.
&lt;/div>
&lt;div id="ref-garcia2013" class="csl-entry">
Garcia, Javier O, Ramesh Srinivasan, and John T Serences. 2013. &lt;span>“Near-Real-Time Feature-Selective Modulations in Human Cortex.”&lt;/span> &lt;em>Current Biology&lt;/em> 23 (6): 515–22.
&lt;/div>
&lt;div id="ref-gardner2019" class="csl-entry">
Gardner, Justin L, and Taosheng Liu. 2019. &lt;span>“Inverted Encoding Models Reconstruct an Arbitrary Model Response, Not the Stimulus.”&lt;/span> &lt;em>eNeuro&lt;/em> 6 (2).
&lt;/div>
&lt;div id="ref-kay2008" class="csl-entry">
Kay, Kendrick N, Thomas Naselaris, Ryan J Prenger, and Jack L Gallant. 2008. &lt;span>“Identifying Natural Images from Human Brain Activity.”&lt;/span> &lt;em>Nature&lt;/em> 452 (7185): 352.
&lt;/div>
&lt;div id="ref-liu2018" class="csl-entry">
Liu, Taosheng, Dylan Cable, and Justin L Gardner. 2018. &lt;span>“Inverted Encoding Models of Human Population Response Conflate Noise and Neural Tuning Width.”&lt;/span> &lt;em>Journal of Neuroscience&lt;/em> 38 (2): 398–408.
&lt;/div>
&lt;div id="ref-mcadams1999" class="csl-entry">
McAdams, Carrie J, and John HR Maunsell. 1999. &lt;span>“Effects of Attention on Orientation-Tuning Functions of Single Neurons in Macaque Cortical Area V4.”&lt;/span> &lt;em>Journal of Neuroscience&lt;/em> 19 (1): 431–41.
&lt;/div>
&lt;div id="ref-rahmati2018" class="csl-entry">
Rahmati, Masih, Golbarg T Saber, and Clayton E Curtis. 2018. &lt;span>“Population Dynamics of Early Visual Cortex During Working Memory.”&lt;/span> &lt;em>Journal of Cognitive Neuroscience&lt;/em> 30 (2): 219–33.
&lt;/div>
&lt;div id="ref-reynolds2000" class="csl-entry">
Reynolds, John H, Tatiana Pasternak, and Robert Desimone. 2000. &lt;span>“Attention Increases Sensitivity of V4 Neurons.”&lt;/span> &lt;em>Neuron&lt;/em> 26 (3): 703–14.
&lt;/div>
&lt;div id="ref-saproo2014" class="csl-entry">
Saproo, Sameer, and John T Serences. 2014. &lt;span>“Attention Improves Transfer of Motion Information Between V1 and MT.”&lt;/span> &lt;em>Journal of Neuroscience&lt;/em> 34 (10): 3586–96.
&lt;/div>
&lt;div id="ref-sclar1982" class="csl-entry">
Sclar, G, and RD Freeman. 1982. &lt;span>“Orientation Selectivity in the Cat’s Striate Cortex Is Invariant with Stimulus Contrast.”&lt;/span> &lt;em>Experimental Brain Research&lt;/em> 46 (3): 457–61.
&lt;/div>
&lt;div id="ref-scolari2012" class="csl-entry">
Scolari, Miranda, Anna Byers, and John T Serences. 2012. &lt;span>“Optimal Deployment of Attentional Gain During Fine Discriminations.”&lt;/span> &lt;em>Journal of Neuroscience&lt;/em> 32 (22): 7723–33.
&lt;/div>
&lt;div id="ref-siegel2015" class="csl-entry">
Siegel, Markus, Timothy J Buschman, and Earl K Miller. 2015. &lt;span>“Cortical Information Flow During Flexible Sensorimotor Decisions.”&lt;/span> &lt;em>Science&lt;/em> 348 (6241): 1352–55.
&lt;/div>
&lt;div id="ref-skottun1987" class="csl-entry">
Skottun, Bernt C, Arthur Bradley, Gary Sclar, Izumi Ohzawa, and Ralph D Freeman. 1987. &lt;span>“The Effects of Contrast on Visual Orientation and Spatial Frequency Discrimination: A Comparison of Single Cells and Behavior.”&lt;/span> &lt;em>Journal of Neurophysiology&lt;/em> 57 (3): 773–86.
&lt;/div>
&lt;div id="ref-sprague2018" class="csl-entry">
Sprague, Thomas C, Kirsten CS Adam, Joshua J Foster, Masih Rahmati, David W Sutterer, and Vy A Vo. 2018. &lt;span>“Inverted Encoding Models Assay Population-Level Stimulus Representations, Not Single-Unit Neural Tuning.”&lt;/span> &lt;em>eNeuro&lt;/em> 5 (3).
&lt;/div>
&lt;div id="ref-sprague2015" class="csl-entry">
Sprague, Thomas C, Sameer Saproo, and John T Serences. 2015. &lt;span>“Visual Attention Mitigates Information Loss in Small-and Large-Scale Neural Codes.”&lt;/span> &lt;em>Trends in Cognitive Sciences&lt;/em> 19 (4): 215–26.
&lt;/div>
&lt;div id="ref-sprague2013" class="csl-entry">
Sprague, Thomas C, and John T Serences. 2013. &lt;span>“Attention Modulates Spatial Priority Maps in the Human Occipital, Parietal and Frontal Cortices.”&lt;/span> &lt;em>Nature Neuroscience&lt;/em> 16 (12): 1879.
&lt;/div>
&lt;div id="ref-vo2017" class="csl-entry">
Vo, Vy A, Thomas C Sprague, and John T Serences. 2017. &lt;span>“Spatial Tuning Shifts Increase the Discriminability and Fidelity of Population Codes in Visual Cortex.”&lt;/span> &lt;em>Journal of Neuroscience&lt;/em> 37 (12): 3386–3401.
&lt;/div>
&lt;div id="ref-yacoub2008" class="csl-entry">
Yacoub, Essa, Noam Harel, and Kâmil Uğurbil. 2008. &lt;span>“High-Field fMRI Unveils Orientation Columns in Humans.”&lt;/span> &lt;em>Proceedings of the National Academy of Sciences&lt;/em> 105 (30): 10607–12.
&lt;/div>
&lt;div id="ref-yang2004" class="csl-entry">
Yang, Tianming, and John HR Maunsell. 2004. &lt;span>“The Effect of Perceptual Learning on Neuronal Responses in Monkey Visual Area V4.”&lt;/span> &lt;em>Journal of Neuroscience&lt;/em> 24 (7): 1617–26.
&lt;/div>
&lt;/div>
&lt;/div></description></item></channel></rss>